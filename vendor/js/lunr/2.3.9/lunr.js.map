{"version":3,"file":"lunr.js","sources":["lunr.js"],"sourcesContent":["var _global = typeof globalThis !== \"undefined\" ? globalThis : typeof self !== \"undefined\" ? self : global;\n\nvar exports = {};\n\n/**\n * lunr - http://lunrjs.com - A bit like Solr, but much smaller and not as bright - 2.3.9\n * Copyright (C) 2020 Oliver Nightingale\n * @license MIT\n */\n;\n\n(function () {\n  /**\n   * A convenience function for configuring and constructing\n   * a new lunr Index.\n   *\n   * A lunr.Builder instance is created and the pipeline setup\n   * with a trimmer, stop word filter and stemmer.\n   *\n   * This builder object is yielded to the configuration function\n   * that is passed as a parameter, allowing the list of fields\n   * and other builder parameters to be customised.\n   *\n   * All documents _must_ be added within the passed config function.\n   *\n   * @example\n   * var idx = lunr(function () {\n   *   this.field('title')\n   *   this.field('body')\n   *   this.ref('id')\n   *\n   *   documents.forEach(function (doc) {\n   *     this.add(doc)\n   *   }, this)\n   * })\n   *\n   * @see {@link lunr.Builder}\n   * @see {@link lunr.Pipeline}\n   * @see {@link lunr.trimmer}\n   * @see {@link lunr.stopWordFilter}\n   * @see {@link lunr.stemmer}\n   * @namespace {function} lunr\n   */\n  var lunr = function (config) {\n    var builder = new lunr.Builder();\n    builder.pipeline.add(lunr.trimmer, lunr.stopWordFilter, lunr.stemmer);\n    builder.searchPipeline.add(lunr.stemmer);\n    config.call(builder, builder);\n    return builder.build();\n  };\n\n  lunr.version = \"2.3.9\";\n  /*!\n   * lunr.utils\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * A namespace containing utils for the rest of the lunr library\n   * @namespace lunr.utils\n   */\n\n  lunr.utils = {};\n  /**\n   * Print a warning message to the console.\n   *\n   * @param {String} message The message to be printed.\n   * @memberOf lunr.utils\n   * @function\n   */\n\n  lunr.utils.warn = function (global) {\n    /* eslint-disable no-console */\n    return function (message) {\n      if (global.console && console.warn) {\n        console.warn(message);\n      }\n    };\n    /* eslint-enable no-console */\n  }(this || _global);\n  /**\n   * Convert an object to a string.\n   *\n   * In the case of `null` and `undefined` the function returns\n   * the empty string, in all other cases the result of calling\n   * `toString` on the passed object is returned.\n   *\n   * @param {Any} obj The object to convert to a string.\n   * @return {String} string representation of the passed object.\n   * @memberOf lunr.utils\n   */\n\n\n  lunr.utils.asString = function (obj) {\n    if (obj === void 0 || obj === null) {\n      return \"\";\n    } else {\n      return obj.toString();\n    }\n  };\n  /**\n   * Clones an object.\n   *\n   * Will create a copy of an existing object such that any mutations\n   * on the copy cannot affect the original.\n   *\n   * Only shallow objects are supported, passing a nested object to this\n   * function will cause a TypeError.\n   *\n   * Objects with primitives, and arrays of primitives are supported.\n   *\n   * @param {Object} obj The object to clone.\n   * @return {Object} a clone of the passed object.\n   * @throws {TypeError} when a nested object is passed.\n   * @memberOf Utils\n   */\n\n\n  lunr.utils.clone = function (obj) {\n    if (obj === null || obj === undefined) {\n      return obj;\n    }\n\n    var clone = Object.create(null),\n        keys = Object.keys(obj);\n\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i],\n          val = obj[key];\n\n      if (Array.isArray(val)) {\n        clone[key] = val.slice();\n        continue;\n      }\n\n      if (typeof val === \"string\" || typeof val === \"number\" || typeof val === \"boolean\") {\n        clone[key] = val;\n        continue;\n      }\n\n      throw new TypeError(\"clone is not deep and does not support nested objects\");\n    }\n\n    return clone;\n  };\n\n  lunr.FieldRef = function (docRef, fieldName, stringValue) {\n    (this || _global).docRef = docRef;\n    (this || _global).fieldName = fieldName;\n    (this || _global)._stringValue = stringValue;\n  };\n\n  lunr.FieldRef.joiner = \"/\";\n\n  lunr.FieldRef.fromString = function (s) {\n    var n = s.indexOf(lunr.FieldRef.joiner);\n\n    if (n === -1) {\n      throw \"malformed field ref string\";\n    }\n\n    var fieldRef = s.slice(0, n),\n        docRef = s.slice(n + 1);\n    return new lunr.FieldRef(docRef, fieldRef, s);\n  };\n\n  lunr.FieldRef.prototype.toString = function () {\n    if ((this || _global)._stringValue == undefined) {\n      (this || _global)._stringValue = (this || _global).fieldName + lunr.FieldRef.joiner + (this || _global).docRef;\n    }\n\n    return (this || _global)._stringValue;\n  };\n  /*!\n   * lunr.Set\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * A lunr set.\n   *\n   * @constructor\n   */\n\n\n  lunr.Set = function (elements) {\n    (this || _global).elements = Object.create(null);\n\n    if (elements) {\n      (this || _global).length = elements.length;\n\n      for (var i = 0; i < (this || _global).length; i++) {\n        (this || _global).elements[elements[i]] = true;\n      }\n    } else {\n      (this || _global).length = 0;\n    }\n  };\n  /**\n   * A complete set that contains all elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n\n\n  lunr.Set.complete = {\n    intersect: function (other) {\n      return other;\n    },\n    union: function () {\n      return this || _global;\n    },\n    contains: function () {\n      return true;\n    }\n  };\n  /**\n   * An empty set that contains no elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n\n  lunr.Set.empty = {\n    intersect: function () {\n      return this || _global;\n    },\n    union: function (other) {\n      return other;\n    },\n    contains: function () {\n      return false;\n    }\n  };\n  /**\n   * Returns true if this set contains the specified object.\n   *\n   * @param {object} object - Object whose presence in this set is to be tested.\n   * @returns {boolean} - True if this set contains the specified object.\n   */\n\n  lunr.Set.prototype.contains = function (object) {\n    return !!(this || _global).elements[object];\n  };\n  /**\n   * Returns a new set containing only the elements that are present in both\n   * this set and the specified set.\n   *\n   * @param {lunr.Set} other - set to intersect with this set.\n   * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\n   */\n\n\n  lunr.Set.prototype.intersect = function (other) {\n    var a,\n        b,\n        elements,\n        intersection = [];\n\n    if (other === lunr.Set.complete) {\n      return this || _global;\n    }\n\n    if (other === lunr.Set.empty) {\n      return other;\n    }\n\n    if ((this || _global).length < other.length) {\n      a = this || _global;\n      b = other;\n    } else {\n      a = other;\n      b = this || _global;\n    }\n\n    elements = Object.keys(a.elements);\n\n    for (var i = 0; i < elements.length; i++) {\n      var element = elements[i];\n\n      if (element in b.elements) {\n        intersection.push(element);\n      }\n    }\n\n    return new lunr.Set(intersection);\n  };\n  /**\n   * Returns a new set combining the elements of this and the specified set.\n   *\n   * @param {lunr.Set} other - set to union with this set.\n   * @return {lunr.Set} a new set that is the union of this and the specified set.\n   */\n\n\n  lunr.Set.prototype.union = function (other) {\n    if (other === lunr.Set.complete) {\n      return lunr.Set.complete;\n    }\n\n    if (other === lunr.Set.empty) {\n      return this || _global;\n    }\n\n    return new lunr.Set(Object.keys((this || _global).elements).concat(Object.keys(other.elements)));\n  };\n  /**\n   * A function to calculate the inverse document frequency for\n   * a posting. This is shared between the builder and the index\n   *\n   * @private\n   * @param {object} posting - The posting for a given term\n   * @param {number} documentCount - The total number of documents.\n   */\n\n\n  lunr.idf = function (posting, documentCount) {\n    var documentsWithTerm = 0;\n\n    for (var fieldName in posting) {\n      if (fieldName == \"_index\") continue; // Ignore the term index, its not a field\n\n      documentsWithTerm += Object.keys(posting[fieldName]).length;\n    }\n\n    var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5);\n    return Math.log(1 + Math.abs(x));\n  };\n  /**\n   * A token wraps a string representation of a token\n   * as it is passed through the text processing pipeline.\n   *\n   * @constructor\n   * @param {string} [str=''] - The string token being wrapped.\n   * @param {object} [metadata={}] - Metadata associated with this token.\n   */\n\n\n  lunr.Token = function (str, metadata) {\n    (this || _global).str = str || \"\";\n    (this || _global).metadata = metadata || {};\n  };\n  /**\n   * Returns the token string that is being wrapped by this object.\n   *\n   * @returns {string}\n   */\n\n\n  lunr.Token.prototype.toString = function () {\n    return (this || _global).str;\n  };\n  /**\n   * A token update function is used when updating or optionally\n   * when cloning a token.\n   *\n   * @callback lunr.Token~updateFunction\n   * @param {string} str - The string representation of the token.\n   * @param {Object} metadata - All metadata associated with this token.\n   */\n\n  /**\n   * Applies the given function to the wrapped string token.\n   *\n   * @example\n   * token.update(function (str, metadata) {\n   *   return str.toUpperCase()\n   * })\n   *\n   * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\n   * @returns {lunr.Token}\n   */\n\n\n  lunr.Token.prototype.update = function (fn) {\n    (this || _global).str = fn((this || _global).str, (this || _global).metadata);\n    return this || _global;\n  };\n  /**\n   * Creates a clone of this token. Optionally a function can be\n   * applied to the cloned token.\n   *\n   * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\n   * @returns {lunr.Token}\n   */\n\n\n  lunr.Token.prototype.clone = function (fn) {\n    fn = fn || function (s) {\n      return s;\n    };\n\n    return new lunr.Token(fn((this || _global).str, (this || _global).metadata), (this || _global).metadata);\n  };\n  /*!\n   * lunr.tokenizer\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * A function for splitting a string into tokens ready to be inserted into\n   * the search index. Uses `lunr.tokenizer.separator` to split strings, change\n   * the value of this property to change how strings are split into tokens.\n   *\n   * This tokenizer will convert its parameter to a string by calling `toString` and\n   * then will split this string on the character in `lunr.tokenizer.separator`.\n   * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\n   *\n   * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\n   * added as metadata to every token that is created from the object to be tokenized.\n   *\n   * @static\n   * @param {?(string|object|object[])} obj - The object to convert into tokens\n   * @param {?object} metadata - Optional metadata to associate with every token\n   * @returns {lunr.Token[]}\n   * @see {@link lunr.Pipeline}\n   */\n\n\n  lunr.tokenizer = function (obj, metadata) {\n    if (obj == null || obj == undefined) {\n      return [];\n    }\n\n    if (Array.isArray(obj)) {\n      return obj.map(function (t) {\n        return new lunr.Token(lunr.utils.asString(t).toLowerCase(), lunr.utils.clone(metadata));\n      });\n    }\n\n    var str = obj.toString().toLowerCase(),\n        len = str.length,\n        tokens = [];\n\n    for (var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++) {\n      var char = str.charAt(sliceEnd),\n          sliceLength = sliceEnd - sliceStart;\n\n      if (char.match(lunr.tokenizer.separator) || sliceEnd == len) {\n        if (sliceLength > 0) {\n          var tokenMetadata = lunr.utils.clone(metadata) || {};\n          tokenMetadata[\"position\"] = [sliceStart, sliceLength];\n          tokenMetadata[\"index\"] = tokens.length;\n          tokens.push(new lunr.Token(str.slice(sliceStart, sliceEnd), tokenMetadata));\n        }\n\n        sliceStart = sliceEnd + 1;\n      }\n    }\n\n    return tokens;\n  };\n  /**\n   * The separator used to split a string into tokens. Override this property to change the behaviour of\n   * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n   *\n   * @static\n   * @see lunr.tokenizer\n   */\n\n\n  lunr.tokenizer.separator = /[\\s\\-]+/;\n  /*!\n   * lunr.Pipeline\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * lunr.Pipelines maintain an ordered list of functions to be applied to all\n   * tokens in documents entering the search index and queries being ran against\n   * the index.\n   *\n   * An instance of lunr.Index created with the lunr shortcut will contain a\n   * pipeline with a stop word filter and an English language stemmer. Extra\n   * functions can be added before or after either of these functions or these\n   * default functions can be removed.\n   *\n   * When run the pipeline will call each function in turn, passing a token, the\n   * index of that token in the original list of all tokens and finally a list of\n   * all the original tokens.\n   *\n   * The output of functions in the pipeline will be passed to the next function\n   * in the pipeline. To exclude a token from entering the index the function\n   * should return undefined, the rest of the pipeline will not be called with\n   * this token.\n   *\n   * For serialisation of pipelines to work, all functions used in an instance of\n   * a pipeline should be registered with lunr.Pipeline. Registered functions can\n   * then be loaded. If trying to load a serialised pipeline that uses functions\n   * that are not registered an error will be thrown.\n   *\n   * If not planning on serialising the pipeline then registering pipeline functions\n   * is not necessary.\n   *\n   * @constructor\n   */\n\n  lunr.Pipeline = function () {\n    (this || _global)._stack = [];\n  };\n\n  lunr.Pipeline.registeredFunctions = Object.create(null);\n  /**\n   * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\n   * string as well as all known metadata. A pipeline function can mutate the token string\n   * or mutate (or add) metadata for a given token.\n   *\n   * A pipeline function can indicate that the passed token should be discarded by returning\n   * null, undefined or an empty string. This token will not be passed to any downstream pipeline\n   * functions and will not be added to the index.\n   *\n   * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\n   * to any downstream pipeline functions and all will returned tokens will be added to the index.\n   *\n   * Any number of pipeline functions may be chained together using a lunr.Pipeline.\n   *\n   * @interface lunr.PipelineFunction\n   * @param {lunr.Token} token - A token from the document being processed.\n   * @param {number} i - The index of this token in the complete list of tokens for this document/field.\n   * @param {lunr.Token[]} tokens - All tokens for this document/field.\n   * @returns {(?lunr.Token|lunr.Token[])}\n   */\n\n  /**\n   * Register a function with the pipeline.\n   *\n   * Functions that are used in the pipeline should be registered if the pipeline\n   * needs to be serialised, or a serialised pipeline needs to be loaded.\n   *\n   * Registering a function does not add it to a pipeline, functions must still be\n   * added to instances of the pipeline for them to be used when running a pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @param {String} label - The label to register this function with\n   */\n\n  lunr.Pipeline.registerFunction = function (fn, label) {\n    if (label in (this || _global).registeredFunctions) {\n      lunr.utils.warn(\"Overwriting existing registered function: \" + label);\n    }\n\n    fn.label = label;\n    lunr.Pipeline.registeredFunctions[fn.label] = fn;\n  };\n  /**\n   * Warns if the function is not registered as a Pipeline function.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @private\n   */\n\n\n  lunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n    var isRegistered = fn.label && fn.label in (this || _global).registeredFunctions;\n\n    if (!isRegistered) {\n      lunr.utils.warn(\"Function is not registered with pipeline. This may cause problems when serialising the index.\\n\", fn);\n    }\n  };\n  /**\n   * Loads a previously serialised pipeline.\n   *\n   * All functions to be loaded must already be registered with lunr.Pipeline.\n   * If any function from the serialised data has not been registered then an\n   * error will be thrown.\n   *\n   * @param {Object} serialised - The serialised pipeline to load.\n   * @returns {lunr.Pipeline}\n   */\n\n\n  lunr.Pipeline.load = function (serialised) {\n    var pipeline = new lunr.Pipeline();\n    serialised.forEach(function (fnName) {\n      var fn = lunr.Pipeline.registeredFunctions[fnName];\n\n      if (fn) {\n        pipeline.add(fn);\n      } else {\n        throw new Error(\"Cannot load unregistered function: \" + fnName);\n      }\n    });\n    return pipeline;\n  };\n  /**\n   * Adds new functions to the end of the pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\n   */\n\n\n  lunr.Pipeline.prototype.add = function () {\n    var fns = Array.prototype.slice.call(arguments);\n    fns.forEach(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn);\n\n      (this || _global)._stack.push(fn);\n    }, this || _global);\n  };\n  /**\n   * Adds a single function after a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n\n\n  lunr.Pipeline.prototype.after = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n    var pos = (this || _global)._stack.indexOf(existingFn);\n\n    if (pos == -1) {\n      throw new Error(\"Cannot find existingFn\");\n    }\n\n    pos = pos + 1;\n\n    (this || _global)._stack.splice(pos, 0, newFn);\n  };\n  /**\n   * Adds a single function before a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n\n\n  lunr.Pipeline.prototype.before = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n    var pos = (this || _global)._stack.indexOf(existingFn);\n\n    if (pos == -1) {\n      throw new Error(\"Cannot find existingFn\");\n    }\n\n    (this || _global)._stack.splice(pos, 0, newFn);\n  };\n  /**\n   * Removes a function from the pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\n   */\n\n\n  lunr.Pipeline.prototype.remove = function (fn) {\n    var pos = (this || _global)._stack.indexOf(fn);\n\n    if (pos == -1) {\n      return;\n    }\n\n    (this || _global)._stack.splice(pos, 1);\n  };\n  /**\n   * Runs the current list of functions that make up the pipeline against the\n   * passed tokens.\n   *\n   * @param {Array} tokens The tokens to run through the pipeline.\n   * @returns {Array}\n   */\n\n\n  lunr.Pipeline.prototype.run = function (tokens) {\n    var stackLength = (this || _global)._stack.length;\n\n    for (var i = 0; i < stackLength; i++) {\n      var fn = (this || _global)._stack[i];\n      var memo = [];\n\n      for (var j = 0; j < tokens.length; j++) {\n        var result = fn(tokens[j], j, tokens);\n        if (result === null || result === void 0 || result === \"\") continue;\n\n        if (Array.isArray(result)) {\n          for (var k = 0; k < result.length; k++) {\n            memo.push(result[k]);\n          }\n        } else {\n          memo.push(result);\n        }\n      }\n\n      tokens = memo;\n    }\n\n    return tokens;\n  };\n  /**\n   * Convenience method for passing a string through a pipeline and getting\n   * strings out. This method takes care of wrapping the passed string in a\n   * token and mapping the resulting tokens back to strings.\n   *\n   * @param {string} str - The string to pass through the pipeline.\n   * @param {?object} metadata - Optional metadata to associate with the token\n   * passed to the pipeline.\n   * @returns {string[]}\n   */\n\n\n  lunr.Pipeline.prototype.runString = function (str, metadata) {\n    var token = new lunr.Token(str, metadata);\n    return this.run([token]).map(function (t) {\n      return t.toString();\n    });\n  };\n  /**\n   * Resets the pipeline by removing any existing processors.\n   *\n   */\n\n\n  lunr.Pipeline.prototype.reset = function () {\n    (this || _global)._stack = [];\n  };\n  /**\n   * Returns a representation of the pipeline ready for serialisation.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @returns {Array}\n   */\n\n\n  lunr.Pipeline.prototype.toJSON = function () {\n    return (this || _global)._stack.map(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn);\n      return fn.label;\n    });\n  };\n  /*!\n   * lunr.Vector\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * A vector is used to construct the vector space of documents and queries. These\n   * vectors support operations to determine the similarity between two documents or\n   * a document and a query.\n   *\n   * Normally no parameters are required for initializing a vector, but in the case of\n   * loading a previously dumped vector the raw elements can be provided to the constructor.\n   *\n   * For performance reasons vectors are implemented with a flat array, where an elements\n   * index is immediately followed by its value. E.g. [index, value, index, value]. This\n   * allows the underlying array to be as sparse as possible and still offer decent\n   * performance when being used for vector calculations.\n   *\n   * @constructor\n   * @param {Number[]} [elements] - The flat list of element index and element value pairs.\n   */\n\n\n  lunr.Vector = function (elements) {\n    (this || _global)._magnitude = 0;\n    (this || _global).elements = elements || [];\n  };\n  /**\n   * Calculates the position within the vector to insert a given index.\n   *\n   * This is used internally by insert and upsert. If there are duplicate indexes then\n   * the position is returned as if the value for that index were to be updated, but it\n   * is the callers responsibility to check whether there is a duplicate at that index\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @returns {Number}\n   */\n\n\n  lunr.Vector.prototype.positionForIndex = function (index) {\n    // For an empty vector the tuple can be inserted at the beginning\n    if ((this || _global).elements.length == 0) {\n      return 0;\n    }\n\n    var start = 0,\n        end = (this || _global).elements.length / 2,\n        sliceLength = end - start,\n        pivotPoint = Math.floor(sliceLength / 2),\n        pivotIndex = (this || _global).elements[pivotPoint * 2];\n\n    while (sliceLength > 1) {\n      if (pivotIndex < index) {\n        start = pivotPoint;\n      }\n\n      if (pivotIndex > index) {\n        end = pivotPoint;\n      }\n\n      if (pivotIndex == index) {\n        break;\n      }\n\n      sliceLength = end - start;\n      pivotPoint = start + Math.floor(sliceLength / 2);\n      pivotIndex = (this || _global).elements[pivotPoint * 2];\n    }\n\n    if (pivotIndex == index) {\n      return pivotPoint * 2;\n    }\n\n    if (pivotIndex > index) {\n      return pivotPoint * 2;\n    }\n\n    if (pivotIndex < index) {\n      return (pivotPoint + 1) * 2;\n    }\n  };\n  /**\n   * Inserts an element at an index within the vector.\n   *\n   * Does not allow duplicates, will throw an error if there is already an entry\n   * for this index.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   */\n\n\n  lunr.Vector.prototype.insert = function (insertIdx, val) {\n    this.upsert(insertIdx, val, function () {\n      throw \"duplicate index\";\n    });\n  };\n  /**\n   * Inserts or updates an existing index within the vector.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   * @param {function} fn - A function that is called for updates, the existing value and the\n   * requested value are passed as arguments\n   */\n\n\n  lunr.Vector.prototype.upsert = function (insertIdx, val, fn) {\n    (this || _global)._magnitude = 0;\n    var position = this.positionForIndex(insertIdx);\n\n    if ((this || _global).elements[position] == insertIdx) {\n      (this || _global).elements[position + 1] = fn((this || _global).elements[position + 1], val);\n    } else {\n      (this || _global).elements.splice(position, 0, insertIdx, val);\n    }\n  };\n  /**\n   * Calculates the magnitude of this vector.\n   *\n   * @returns {Number}\n   */\n\n\n  lunr.Vector.prototype.magnitude = function () {\n    if ((this || _global)._magnitude) return (this || _global)._magnitude;\n    var sumOfSquares = 0,\n        elementsLength = (this || _global).elements.length;\n\n    for (var i = 1; i < elementsLength; i += 2) {\n      var val = (this || _global).elements[i];\n      sumOfSquares += val * val;\n    }\n\n    return (this || _global)._magnitude = Math.sqrt(sumOfSquares);\n  };\n  /**\n   * Calculates the dot product of this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\n   * @returns {Number}\n   */\n\n\n  lunr.Vector.prototype.dot = function (otherVector) {\n    var dotProduct = 0,\n        a = (this || _global).elements,\n        b = otherVector.elements,\n        aLen = a.length,\n        bLen = b.length,\n        aVal = 0,\n        bVal = 0,\n        i = 0,\n        j = 0;\n\n    while (i < aLen && j < bLen) {\n      aVal = a[i], bVal = b[j];\n\n      if (aVal < bVal) {\n        i += 2;\n      } else if (aVal > bVal) {\n        j += 2;\n      } else if (aVal == bVal) {\n        dotProduct += a[i + 1] * b[j + 1];\n        i += 2;\n        j += 2;\n      }\n    }\n\n    return dotProduct;\n  };\n  /**\n   * Calculates the similarity between this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The other vector to calculate the\n   * similarity with.\n   * @returns {Number}\n   */\n\n\n  lunr.Vector.prototype.similarity = function (otherVector) {\n    return this.dot(otherVector) / this.magnitude() || 0;\n  };\n  /**\n   * Converts the vector to an array of the elements within the vector.\n   *\n   * @returns {Number[]}\n   */\n\n\n  lunr.Vector.prototype.toArray = function () {\n    var output = new Array((this || _global).elements.length / 2);\n\n    for (var i = 1, j = 0; i < (this || _global).elements.length; i += 2, j++) {\n      output[j] = (this || _global).elements[i];\n    }\n\n    return output;\n  };\n  /**\n   * A JSON serializable representation of the vector.\n   *\n   * @returns {Number[]}\n   */\n\n\n  lunr.Vector.prototype.toJSON = function () {\n    return (this || _global).elements;\n  };\n  /* eslint-disable */\n\n  /*!\n   * lunr.stemmer\n   * Copyright (C) 2020 Oliver Nightingale\n   * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n   */\n\n  /**\n   * lunr.stemmer is an english language stemmer, this is a JavaScript\n   * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token - The string to stem\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   * @function\n   */\n\n\n  lunr.stemmer = function () {\n    var step2list = {\n      \"ational\": \"ate\",\n      \"tional\": \"tion\",\n      \"enci\": \"ence\",\n      \"anci\": \"ance\",\n      \"izer\": \"ize\",\n      \"bli\": \"ble\",\n      \"alli\": \"al\",\n      \"entli\": \"ent\",\n      \"eli\": \"e\",\n      \"ousli\": \"ous\",\n      \"ization\": \"ize\",\n      \"ation\": \"ate\",\n      \"ator\": \"ate\",\n      \"alism\": \"al\",\n      \"iveness\": \"ive\",\n      \"fulness\": \"ful\",\n      \"ousness\": \"ous\",\n      \"aliti\": \"al\",\n      \"iviti\": \"ive\",\n      \"biliti\": \"ble\",\n      \"logi\": \"log\"\n    },\n        step3list = {\n      \"icate\": \"ic\",\n      \"ative\": \"\",\n      \"alize\": \"al\",\n      \"iciti\": \"ic\",\n      \"ical\": \"ic\",\n      \"ful\": \"\",\n      \"ness\": \"\"\n    },\n        c = \"[^aeiou]\",\n        // consonant\n    v = \"[aeiouy]\",\n        // vowel\n    C = c + \"[^aeiouy]*\",\n        // consonant sequence\n    V = v + \"[aeiou]*\",\n        // vowel sequence\n    mgr0 = \"^(\" + C + \")?\" + V + C,\n        // [C]VC... is m>0\n    meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",\n        // [C]VC[V] is m=1\n    mgr1 = \"^(\" + C + \")?\" + V + C + V + C,\n        // [C]VCVC... is m>1\n    s_v = \"^(\" + C + \")?\" + v; // vowel in stem\n\n    var re_mgr0 = new RegExp(mgr0);\n    var re_mgr1 = new RegExp(mgr1);\n    var re_meq1 = new RegExp(meq1);\n    var re_s_v = new RegExp(s_v);\n    var re_1a = /^(.+?)(ss|i)es$/;\n    var re2_1a = /^(.+?)([^s])s$/;\n    var re_1b = /^(.+?)eed$/;\n    var re2_1b = /^(.+?)(ed|ing)$/;\n    var re_1b_2 = /.$/;\n    var re2_1b_2 = /(at|bl|iz)$/;\n    var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n    var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n    var re_1c = /^(.+?[^aeiou])y$/;\n    var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n    var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n    var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n    var re2_4 = /^(.+?)(s|t)(ion)$/;\n    var re_5 = /^(.+?)e$/;\n    var re_5_1 = /ll$/;\n    var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n    var porterStemmer = function porterStemmer(w) {\n      var stem, suffix, firstch, re, re2, re3, re4;\n\n      if (w.length < 3) {\n        return w;\n      }\n\n      firstch = w.substr(0, 1);\n\n      if (firstch == \"y\") {\n        w = firstch.toUpperCase() + w.substr(1);\n      } // Step 1a\n\n\n      re = re_1a;\n      re2 = re2_1a;\n\n      if (re.test(w)) {\n        w = w.replace(re, \"$1$2\");\n      } else if (re2.test(w)) {\n        w = w.replace(re2, \"$1$2\");\n      } // Step 1b\n\n\n      re = re_1b;\n      re2 = re2_1b;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        re = re_mgr0;\n\n        if (re.test(fp[1])) {\n          re = re_1b_2;\n          w = w.replace(re, \"\");\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1];\n        re2 = re_s_v;\n\n        if (re2.test(stem)) {\n          w = stem;\n          re2 = re2_1b_2;\n          re3 = re3_1b_2;\n          re4 = re4_1b_2;\n\n          if (re2.test(w)) {\n            w = w + \"e\";\n          } else if (re3.test(w)) {\n            re = re_1b_2;\n            w = w.replace(re, \"\");\n          } else if (re4.test(w)) {\n            w = w + \"e\";\n          }\n        }\n      } // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n\n\n      re = re_1c;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        w = stem + \"i\";\n      } // Step 2\n\n\n      re = re_2;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n\n        if (re.test(stem)) {\n          w = stem + step2list[suffix];\n        }\n      } // Step 3\n\n\n      re = re_3;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n\n        if (re.test(stem)) {\n          w = stem + step3list[suffix];\n        }\n      } // Step 4\n\n\n      re = re_4;\n      re2 = re2_4;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n\n        if (re.test(stem)) {\n          w = stem;\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1] + fp[2];\n        re2 = re_mgr1;\n\n        if (re2.test(stem)) {\n          w = stem;\n        }\n      } // Step 5\n\n\n      re = re_5;\n\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n        re2 = re_meq1;\n        re3 = re3_5;\n\n        if (re.test(stem) || re2.test(stem) && !re3.test(stem)) {\n          w = stem;\n        }\n      }\n\n      re = re_5_1;\n      re2 = re_mgr1;\n\n      if (re.test(w) && re2.test(w)) {\n        re = re_1b_2;\n        w = w.replace(re, \"\");\n      } // and turn initial Y back to y\n\n\n      if (firstch == \"y\") {\n        w = firstch.toLowerCase() + w.substr(1);\n      }\n\n      return w;\n    };\n\n    return function (token) {\n      return token.update(porterStemmer);\n    };\n  }();\n\n  lunr.Pipeline.registerFunction(lunr.stemmer, \"stemmer\");\n  /*!\n   * lunr.stopWordFilter\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\n   * list of stop words.\n   *\n   * The built in lunr.stopWordFilter is built using this generator and can be used\n   * to generate custom stopWordFilters for applications or non English languages.\n   *\n   * @function\n   * @param {Array} token The token to pass through the filter\n   * @returns {lunr.PipelineFunction}\n   * @see lunr.Pipeline\n   * @see lunr.stopWordFilter\n   */\n\n  lunr.generateStopWordFilter = function (stopWords) {\n    var words = stopWords.reduce(function (memo, stopWord) {\n      memo[stopWord] = stopWord;\n      return memo;\n    }, {});\n    return function (token) {\n      if (token && words[token.toString()] !== token.toString()) return token;\n    };\n  };\n  /**\n   * lunr.stopWordFilter is an English language stop word list filter, any words\n   * contained in the list will not be passed through the filter.\n   *\n   * This is intended to be used in the Pipeline. If the token does not pass the\n   * filter then undefined will be returned.\n   *\n   * @function\n   * @implements {lunr.PipelineFunction}\n   * @params {lunr.Token} token - A token to check for being a stop word.\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   */\n\n\n  lunr.stopWordFilter = lunr.generateStopWordFilter([\"a\", \"able\", \"about\", \"across\", \"after\", \"all\", \"almost\", \"also\", \"am\", \"among\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"but\", \"by\", \"can\", \"cannot\", \"could\", \"dear\", \"did\", \"do\", \"does\", \"either\", \"else\", \"ever\", \"every\", \"for\", \"from\", \"get\", \"got\", \"had\", \"has\", \"have\", \"he\", \"her\", \"hers\", \"him\", \"his\", \"how\", \"however\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"just\", \"least\", \"let\", \"like\", \"likely\", \"may\", \"me\", \"might\", \"most\", \"must\", \"my\", \"neither\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"often\", \"on\", \"only\", \"or\", \"other\", \"our\", \"own\", \"rather\", \"said\", \"say\", \"says\", \"she\", \"should\", \"since\", \"so\", \"some\", \"than\", \"that\", \"the\", \"their\", \"them\", \"then\", \"there\", \"these\", \"they\", \"this\", \"tis\", \"to\", \"too\", \"twas\", \"us\", \"wants\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"would\", \"yet\", \"you\", \"your\"]);\n  lunr.Pipeline.registerFunction(lunr.stopWordFilter, \"stopWordFilter\");\n  /*!\n   * lunr.trimmer\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * lunr.trimmer is a pipeline function for trimming non word\n   * characters from the beginning and end of tokens before they\n   * enter the index.\n   *\n   * This implementation may not work correctly for non latin\n   * characters and should either be removed or adapted for use\n   * with languages with non-latin characters.\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token The token to pass through the filter\n   * @returns {lunr.Token}\n   * @see lunr.Pipeline\n   */\n\n  lunr.trimmer = function (token) {\n    return token.update(function (s) {\n      return s.replace(/^\\W+/, \"\").replace(/\\W+$/, \"\");\n    });\n  };\n\n  lunr.Pipeline.registerFunction(lunr.trimmer, \"trimmer\");\n  /*!\n   * lunr.TokenSet\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * A token set is used to store the unique list of all tokens\n   * within an index. Token sets are also used to represent an\n   * incoming query to the index, this query token set and index\n   * token set are then intersected to find which tokens to look\n   * up in the inverted index.\n   *\n   * A token set can hold multiple tokens, as in the case of the\n   * index token set, or it can hold a single token as in the\n   * case of a simple query token set.\n   *\n   * Additionally token sets are used to perform wildcard matching.\n   * Leading, contained and trailing wildcards are supported, and\n   * from this edit distance matching can also be provided.\n   *\n   * Token sets are implemented as a minimal finite state automata,\n   * where both common prefixes and suffixes are shared between tokens.\n   * This helps to reduce the space used for storing the token set.\n   *\n   * @constructor\n   */\n\n  lunr.TokenSet = function () {\n    (this || _global).final = false;\n    (this || _global).edges = {};\n    (this || _global).id = lunr.TokenSet._nextId;\n    lunr.TokenSet._nextId += 1;\n  };\n  /**\n   * Keeps track of the next, auto increment, identifier to assign\n   * to a new tokenSet.\n   *\n   * TokenSets require a unique identifier to be correctly minimised.\n   *\n   * @private\n   */\n\n\n  lunr.TokenSet._nextId = 1;\n  /**\n   * Creates a TokenSet instance from the given sorted array of words.\n   *\n   * @param {String[]} arr - A sorted array of strings to create the set from.\n   * @returns {lunr.TokenSet}\n   * @throws Will throw an error if the input array is not sorted.\n   */\n\n  lunr.TokenSet.fromArray = function (arr) {\n    var builder = new lunr.TokenSet.Builder();\n\n    for (var i = 0, len = arr.length; i < len; i++) {\n      builder.insert(arr[i]);\n    }\n\n    builder.finish();\n    return builder.root;\n  };\n  /**\n   * Creates a token set from a query clause.\n   *\n   * @private\n   * @param {Object} clause - A single clause from lunr.Query.\n   * @param {string} clause.term - The query clause term.\n   * @param {number} [clause.editDistance] - The optional edit distance for the term.\n   * @returns {lunr.TokenSet}\n   */\n\n\n  lunr.TokenSet.fromClause = function (clause) {\n    if (\"editDistance\" in clause) {\n      return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance);\n    } else {\n      return lunr.TokenSet.fromString(clause.term);\n    }\n  };\n  /**\n   * Creates a token set representing a single string with a specified\n   * edit distance.\n   *\n   * Insertions, deletions, substitutions and transpositions are each\n   * treated as an edit distance of 1.\n   *\n   * Increasing the allowed edit distance will have a dramatic impact\n   * on the performance of both creating and intersecting these TokenSets.\n   * It is advised to keep the edit distance less than 3.\n   *\n   * @param {string} str - The string to create the token set from.\n   * @param {number} editDistance - The allowed edit distance to match.\n   * @returns {lunr.Vector}\n   */\n\n\n  lunr.TokenSet.fromFuzzyString = function (str, editDistance) {\n    var root = new lunr.TokenSet();\n    var stack = [{\n      node: root,\n      editsRemaining: editDistance,\n      str: str\n    }];\n\n    while (stack.length) {\n      var frame = stack.pop(); // no edit\n\n      if (frame.str.length > 0) {\n        var char = frame.str.charAt(0),\n            noEditNode;\n\n        if (char in frame.node.edges) {\n          noEditNode = frame.node.edges[char];\n        } else {\n          noEditNode = new lunr.TokenSet();\n          frame.node.edges[char] = noEditNode;\n        }\n\n        if (frame.str.length == 1) {\n          noEditNode.final = true;\n        }\n\n        stack.push({\n          node: noEditNode,\n          editsRemaining: frame.editsRemaining,\n          str: frame.str.slice(1)\n        });\n      }\n\n      if (frame.editsRemaining == 0) {\n        continue;\n      } // insertion\n\n\n      if (\"*\" in frame.node.edges) {\n        var insertionNode = frame.node.edges[\"*\"];\n      } else {\n        var insertionNode = new lunr.TokenSet();\n        frame.node.edges[\"*\"] = insertionNode;\n      }\n\n      if (frame.str.length == 0) {\n        insertionNode.final = true;\n      }\n\n      stack.push({\n        node: insertionNode,\n        editsRemaining: frame.editsRemaining - 1,\n        str: frame.str\n      }); // deletion\n      // can only do a deletion if we have enough edits remaining\n      // and if there are characters left to delete in the string\n\n      if (frame.str.length > 1) {\n        stack.push({\n          node: frame.node,\n          editsRemaining: frame.editsRemaining - 1,\n          str: frame.str.slice(1)\n        });\n      } // deletion\n      // just removing the last character from the str\n\n\n      if (frame.str.length == 1) {\n        frame.node.final = true;\n      } // substitution\n      // can only do a substitution if we have enough edits remaining\n      // and if there are characters left to substitute\n\n\n      if (frame.str.length >= 1) {\n        if (\"*\" in frame.node.edges) {\n          var substitutionNode = frame.node.edges[\"*\"];\n        } else {\n          var substitutionNode = new lunr.TokenSet();\n          frame.node.edges[\"*\"] = substitutionNode;\n        }\n\n        if (frame.str.length == 1) {\n          substitutionNode.final = true;\n        }\n\n        stack.push({\n          node: substitutionNode,\n          editsRemaining: frame.editsRemaining - 1,\n          str: frame.str.slice(1)\n        });\n      } // transposition\n      // can only do a transposition if there are edits remaining\n      // and there are enough characters to transpose\n\n\n      if (frame.str.length > 1) {\n        var charA = frame.str.charAt(0),\n            charB = frame.str.charAt(1),\n            transposeNode;\n\n        if (charB in frame.node.edges) {\n          transposeNode = frame.node.edges[charB];\n        } else {\n          transposeNode = new lunr.TokenSet();\n          frame.node.edges[charB] = transposeNode;\n        }\n\n        if (frame.str.length == 1) {\n          transposeNode.final = true;\n        }\n\n        stack.push({\n          node: transposeNode,\n          editsRemaining: frame.editsRemaining - 1,\n          str: charA + frame.str.slice(2)\n        });\n      }\n    }\n\n    return root;\n  };\n  /**\n   * Creates a TokenSet from a string.\n   *\n   * The string may contain one or more wildcard characters (*)\n   * that will allow wildcard matching when intersecting with\n   * another TokenSet.\n   *\n   * @param {string} str - The string to create a TokenSet from.\n   * @returns {lunr.TokenSet}\n   */\n\n\n  lunr.TokenSet.fromString = function (str) {\n    var node = new lunr.TokenSet(),\n        root = node;\n    /*\n     * Iterates through all characters within the passed string\n     * appending a node for each character.\n     *\n     * When a wildcard character is found then a self\n     * referencing edge is introduced to continually match\n     * any number of any characters.\n     */\n\n    for (var i = 0, len = str.length; i < len; i++) {\n      var char = str[i],\n          final = i == len - 1;\n\n      if (char == \"*\") {\n        node.edges[char] = node;\n        node.final = final;\n      } else {\n        var next = new lunr.TokenSet();\n        next.final = final;\n        node.edges[char] = next;\n        node = next;\n      }\n    }\n\n    return root;\n  };\n  /**\n   * Converts this TokenSet into an array of strings\n   * contained within the TokenSet.\n   *\n   * This is not intended to be used on a TokenSet that\n   * contains wildcards, in these cases the results are\n   * undefined and are likely to cause an infinite loop.\n   *\n   * @returns {string[]}\n   */\n\n\n  lunr.TokenSet.prototype.toArray = function () {\n    var words = [];\n    var stack = [{\n      prefix: \"\",\n      node: this || _global\n    }];\n\n    while (stack.length) {\n      var frame = stack.pop(),\n          edges = Object.keys(frame.node.edges),\n          len = edges.length;\n\n      if (frame.node.final) {\n        /* In Safari, at this point the prefix is sometimes corrupted, see:\n         * https://github.com/olivernn/lunr.js/issues/279 Calling any\n         * String.prototype method forces Safari to \"cast\" this string to what\n         * it's supposed to be, fixing the bug. */\n        frame.prefix.charAt(0);\n        words.push(frame.prefix);\n      }\n\n      for (var i = 0; i < len; i++) {\n        var edge = edges[i];\n        stack.push({\n          prefix: frame.prefix.concat(edge),\n          node: frame.node.edges[edge]\n        });\n      }\n    }\n\n    return words;\n  };\n  /**\n   * Generates a string representation of a TokenSet.\n   *\n   * This is intended to allow TokenSets to be used as keys\n   * in objects, largely to aid the construction and minimisation\n   * of a TokenSet. As such it is not designed to be a human\n   * friendly representation of the TokenSet.\n   *\n   * @returns {string}\n   */\n\n\n  lunr.TokenSet.prototype.toString = function () {\n    // NOTE: Using Object.keys here as this.edges is very likely\n    // to enter 'hash-mode' with many keys being added\n    //\n    // avoiding a for-in loop here as it leads to the function\n    // being de-optimised (at least in V8). From some simple\n    // benchmarks the performance is comparable, but allowing\n    // V8 to optimize may mean easy performance wins in the future.\n    if ((this || _global)._str) {\n      return (this || _global)._str;\n    }\n\n    var str = (this || _global).final ? \"1\" : \"0\",\n        labels = Object.keys((this || _global).edges).sort(),\n        len = labels.length;\n\n    for (var i = 0; i < len; i++) {\n      var label = labels[i],\n          node = (this || _global).edges[label];\n      str = str + label + node.id;\n    }\n\n    return str;\n  };\n  /**\n   * Returns a new TokenSet that is the intersection of\n   * this TokenSet and the passed TokenSet.\n   *\n   * This intersection will take into account any wildcards\n   * contained within the TokenSet.\n   *\n   * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\n   * @returns {lunr.TokenSet}\n   */\n\n\n  lunr.TokenSet.prototype.intersect = function (b) {\n    var output = new lunr.TokenSet(),\n        frame = undefined;\n    var stack = [{\n      qNode: b,\n      output: output,\n      node: this || _global\n    }];\n\n    while (stack.length) {\n      frame = stack.pop(); // NOTE: As with the #toString method, we are using\n      // Object.keys and a for loop instead of a for-in loop\n      // as both of these objects enter 'hash' mode, causing\n      // the function to be de-optimised in V8\n\n      var qEdges = Object.keys(frame.qNode.edges),\n          qLen = qEdges.length,\n          nEdges = Object.keys(frame.node.edges),\n          nLen = nEdges.length;\n\n      for (var q = 0; q < qLen; q++) {\n        var qEdge = qEdges[q];\n\n        for (var n = 0; n < nLen; n++) {\n          var nEdge = nEdges[n];\n\n          if (nEdge == qEdge || qEdge == \"*\") {\n            var node = frame.node.edges[nEdge],\n                qNode = frame.qNode.edges[qEdge],\n                final = node.final && qNode.final,\n                next = undefined;\n\n            if (nEdge in frame.output.edges) {\n              // an edge already exists for this character\n              // no need to create a new node, just set the finality\n              // bit unless this node is already final\n              next = frame.output.edges[nEdge];\n              next.final = next.final || final;\n            } else {\n              // no edge exists yet, must create one\n              // set the finality bit and insert it\n              // into the output\n              next = new lunr.TokenSet();\n              next.final = final;\n              frame.output.edges[nEdge] = next;\n            }\n\n            stack.push({\n              qNode: qNode,\n              output: next,\n              node: node\n            });\n          }\n        }\n      }\n    }\n\n    return output;\n  };\n\n  lunr.TokenSet.Builder = function () {\n    (this || _global).previousWord = \"\";\n    (this || _global).root = new lunr.TokenSet();\n    (this || _global).uncheckedNodes = [];\n    (this || _global).minimizedNodes = {};\n  };\n\n  lunr.TokenSet.Builder.prototype.insert = function (word) {\n    var node,\n        commonPrefix = 0;\n\n    if (word < (this || _global).previousWord) {\n      throw new Error(\"Out of order word insertion\");\n    }\n\n    for (var i = 0; i < word.length && i < (this || _global).previousWord.length; i++) {\n      if (word[i] != (this || _global).previousWord[i]) break;\n      commonPrefix++;\n    }\n\n    this.minimize(commonPrefix);\n\n    if ((this || _global).uncheckedNodes.length == 0) {\n      node = (this || _global).root;\n    } else {\n      node = (this || _global).uncheckedNodes[(this || _global).uncheckedNodes.length - 1].child;\n    }\n\n    for (var i = commonPrefix; i < word.length; i++) {\n      var nextNode = new lunr.TokenSet(),\n          char = word[i];\n      node.edges[char] = nextNode;\n\n      (this || _global).uncheckedNodes.push({\n        parent: node,\n        char: char,\n        child: nextNode\n      });\n\n      node = nextNode;\n    }\n\n    node.final = true;\n    (this || _global).previousWord = word;\n  };\n\n  lunr.TokenSet.Builder.prototype.finish = function () {\n    this.minimize(0);\n  };\n\n  lunr.TokenSet.Builder.prototype.minimize = function (downTo) {\n    for (var i = (this || _global).uncheckedNodes.length - 1; i >= downTo; i--) {\n      var node = (this || _global).uncheckedNodes[i],\n          childKey = node.child.toString();\n\n      if (childKey in (this || _global).minimizedNodes) {\n        node.parent.edges[node.char] = (this || _global).minimizedNodes[childKey];\n      } else {\n        // Cache the key for this node since\n        // we know it can't change anymore\n        node.child._str = childKey;\n        (this || _global).minimizedNodes[childKey] = node.child;\n      }\n\n      (this || _global).uncheckedNodes.pop();\n    }\n  };\n  /*!\n   * lunr.Index\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * An index contains the built index of all documents and provides a query interface\n   * to the index.\n   *\n   * Usually instances of lunr.Index will not be created using this constructor, instead\n   * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\n   * used to load previously built and serialized indexes.\n   *\n   * @constructor\n   * @param {Object} attrs - The attributes of the built search index.\n   * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\n   * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\n   * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\n   * @param {string[]} attrs.fields - The names of indexed document fields.\n   * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\n   */\n\n\n  lunr.Index = function (attrs) {\n    (this || _global).invertedIndex = attrs.invertedIndex;\n    (this || _global).fieldVectors = attrs.fieldVectors;\n    (this || _global).tokenSet = attrs.tokenSet;\n    (this || _global).fields = attrs.fields;\n    (this || _global).pipeline = attrs.pipeline;\n  };\n  /**\n   * A result contains details of a document matching a search query.\n   * @typedef {Object} lunr.Index~Result\n   * @property {string} ref - The reference of the document this result represents.\n   * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\n   * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\n   */\n\n  /**\n   * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\n   * query language which itself is parsed into an instance of lunr.Query.\n   *\n   * For programmatically building queries it is advised to directly use lunr.Query, the query language\n   * is best used for human entered text rather than program generated text.\n   *\n   * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\n   * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\n   * or 'world', though those that contain both will rank higher in the results.\n   *\n   * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\n   * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\n   * wildcards will increase the number of documents that will be found but can also have a negative\n   * impact on query performance, especially with wildcards at the beginning of a term.\n   *\n   * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\n   * hello in the title field will match this query. Using a field not present in the index will lead\n   * to an error being thrown.\n   *\n   * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\n   * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\n   * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\n   * Avoid large values for edit distance to improve query performance.\n   *\n   * Each term also supports a presence modifier. By default a term's presence in document is optional, however\n   * this can be changed to either required or prohibited. For a term's presence to be required in a document the\n   * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\n   * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\n   * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\n   *\n   * To escape special characters the backslash character '\\' can be used, this allows searches to include\n   * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\n   * of attempting to apply a boost of 2 to the search term \"foo\".\n   *\n   * @typedef {string} lunr.Index~QueryString\n   * @example <caption>Simple single term query</caption>\n   * hello\n   * @example <caption>Multiple term query</caption>\n   * hello world\n   * @example <caption>term scoped to a field</caption>\n   * title:hello\n   * @example <caption>term with a boost of 10</caption>\n   * hello^10\n   * @example <caption>term with an edit distance of 2</caption>\n   * hello~2\n   * @example <caption>terms with presence modifiers</caption>\n   * -foo +bar baz\n   */\n\n  /**\n   * Performs a search against the index using lunr query syntax.\n   *\n   * Results will be returned sorted by their score, the most relevant results\n   * will be returned first.  For details on how the score is calculated, please see\n   * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\n   *\n   * For more programmatic querying use lunr.Index#query.\n   *\n   * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\n   * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\n   * @returns {lunr.Index~Result[]}\n   */\n\n\n  lunr.Index.prototype.search = function (queryString) {\n    return this.query(function (query) {\n      var parser = new lunr.QueryParser(queryString, query);\n      parser.parse();\n    });\n  };\n  /**\n   * A query builder callback provides a query object to be used to express\n   * the query to perform on the index.\n   *\n   * @callback lunr.Index~queryBuilder\n   * @param {lunr.Query} query - The query object to build up.\n   * @this lunr.Query\n   */\n\n  /**\n   * Performs a query against the index using the yielded lunr.Query object.\n   *\n   * If performing programmatic queries against the index, this method is preferred\n   * over lunr.Index#search so as to avoid the additional query parsing overhead.\n   *\n   * A query object is yielded to the supplied function which should be used to\n   * express the query to be run against the index.\n   *\n   * Note that although this function takes a callback parameter it is _not_ an\n   * asynchronous operation, the callback is just yielded a query object to be\n   * customized.\n   *\n   * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\n   * @returns {lunr.Index~Result[]}\n   */\n\n\n  lunr.Index.prototype.query = function (fn) {\n    // for each query clause\n    // * process terms\n    // * expand terms from token set\n    // * find matching documents and metadata\n    // * get document vectors\n    // * score documents\n    var query = new lunr.Query((this || _global).fields),\n        matchingFields = Object.create(null),\n        queryVectors = Object.create(null),\n        termFieldCache = Object.create(null),\n        requiredMatches = Object.create(null),\n        prohibitedMatches = Object.create(null);\n    /*\n     * To support field level boosts a query vector is created per\n     * field. An empty vector is eagerly created to support negated\n     * queries.\n     */\n\n    for (var i = 0; i < (this || _global).fields.length; i++) {\n      queryVectors[(this || _global).fields[i]] = new lunr.Vector();\n    }\n\n    fn.call(query, query);\n\n    for (var i = 0; i < query.clauses.length; i++) {\n      /*\n       * Unless the pipeline has been disabled for this term, which is\n       * the case for terms with wildcards, we need to pass the clause\n       * term through the search pipeline. A pipeline returns an array\n       * of processed terms. Pipeline functions may expand the passed\n       * term, which means we may end up performing multiple index lookups\n       * for a single query term.\n       */\n      var clause = query.clauses[i],\n          terms = null,\n          clauseMatches = lunr.Set.empty;\n\n      if (clause.usePipeline) {\n        terms = (this || _global).pipeline.runString(clause.term, {\n          fields: clause.fields\n        });\n      } else {\n        terms = [clause.term];\n      }\n\n      for (var m = 0; m < terms.length; m++) {\n        var term = terms[m];\n        /*\n         * Each term returned from the pipeline needs to use the same query\n         * clause object, e.g. the same boost and or edit distance. The\n         * simplest way to do this is to re-use the clause object but mutate\n         * its term property.\n         */\n\n        clause.term = term;\n        /*\n         * From the term in the clause we create a token set which will then\n         * be used to intersect the indexes token set to get a list of terms\n         * to lookup in the inverted index\n         */\n\n        var termTokenSet = lunr.TokenSet.fromClause(clause),\n            expandedTerms = (this || _global).tokenSet.intersect(termTokenSet).toArray();\n        /*\n         * If a term marked as required does not exist in the tokenSet it is\n         * impossible for the search to return any matches. We set all the field\n         * scoped required matches set to empty and stop examining any further\n         * clauses.\n         */\n\n\n        if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\n          for (var k = 0; k < clause.fields.length; k++) {\n            var field = clause.fields[k];\n            requiredMatches[field] = lunr.Set.empty;\n          }\n\n          break;\n        }\n\n        for (var j = 0; j < expandedTerms.length; j++) {\n          /*\n           * For each term get the posting and termIndex, this is required for\n           * building the query vector.\n           */\n          var expandedTerm = expandedTerms[j],\n              posting = (this || _global).invertedIndex[expandedTerm],\n              termIndex = posting._index;\n\n          for (var k = 0; k < clause.fields.length; k++) {\n            /*\n             * For each field that this query term is scoped by (by default\n             * all fields are in scope) we need to get all the document refs\n             * that have this term in that field.\n             *\n             * The posting is the entry in the invertedIndex for the matching\n             * term from above.\n             */\n            var field = clause.fields[k],\n                fieldPosting = posting[field],\n                matchingDocumentRefs = Object.keys(fieldPosting),\n                termField = expandedTerm + \"/\" + field,\n                matchingDocumentsSet = new lunr.Set(matchingDocumentRefs);\n            /*\n             * if the presence of this term is required ensure that the matching\n             * documents are added to the set of required matches for this clause.\n             *\n             */\n\n            if (clause.presence == lunr.Query.presence.REQUIRED) {\n              clauseMatches = clauseMatches.union(matchingDocumentsSet);\n\n              if (requiredMatches[field] === undefined) {\n                requiredMatches[field] = lunr.Set.complete;\n              }\n            }\n            /*\n             * if the presence of this term is prohibited ensure that the matching\n             * documents are added to the set of prohibited matches for this field,\n             * creating that set if it does not yet exist.\n             */\n\n\n            if (clause.presence == lunr.Query.presence.PROHIBITED) {\n              if (prohibitedMatches[field] === undefined) {\n                prohibitedMatches[field] = lunr.Set.empty;\n              }\n\n              prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet);\n              /*\n               * Prohibited matches should not be part of the query vector used for\n               * similarity scoring and no metadata should be extracted so we continue\n               * to the next field\n               */\n\n              continue;\n            }\n            /*\n             * The query field vector is populated using the termIndex found for\n             * the term and a unit value with the appropriate boost applied.\n             * Using upsert because there could already be an entry in the vector\n             * for the term we are working with. In that case we just add the scores\n             * together.\n             */\n\n\n            queryVectors[field].upsert(termIndex, clause.boost, function (a, b) {\n              return a + b;\n            });\n            /**\n             * If we've already seen this term, field combo then we've already collected\n             * the matching documents and metadata, no need to go through all that again\n             */\n\n            if (termFieldCache[termField]) {\n              continue;\n            }\n\n            for (var l = 0; l < matchingDocumentRefs.length; l++) {\n              /*\n               * All metadata for this term/field/document triple\n               * are then extracted and collected into an instance\n               * of lunr.MatchData ready to be returned in the query\n               * results\n               */\n              var matchingDocumentRef = matchingDocumentRefs[l],\n                  matchingFieldRef = new lunr.FieldRef(matchingDocumentRef, field),\n                  metadata = fieldPosting[matchingDocumentRef],\n                  fieldMatch;\n\n              if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) {\n                matchingFields[matchingFieldRef] = new lunr.MatchData(expandedTerm, field, metadata);\n              } else {\n                fieldMatch.add(expandedTerm, field, metadata);\n              }\n            }\n\n            termFieldCache[termField] = true;\n          }\n        }\n      }\n      /**\n       * If the presence was required we need to update the requiredMatches field sets.\n       * We do this after all fields for the term have collected their matches because\n       * the clause terms presence is required in _any_ of the fields not _all_ of the\n       * fields.\n       */\n\n\n      if (clause.presence === lunr.Query.presence.REQUIRED) {\n        for (var k = 0; k < clause.fields.length; k++) {\n          var field = clause.fields[k];\n          requiredMatches[field] = requiredMatches[field].intersect(clauseMatches);\n        }\n      }\n    }\n    /**\n     * Need to combine the field scoped required and prohibited\n     * matching documents into a global set of required and prohibited\n     * matches\n     */\n\n\n    var allRequiredMatches = lunr.Set.complete,\n        allProhibitedMatches = lunr.Set.empty;\n\n    for (var i = 0; i < (this || _global).fields.length; i++) {\n      var field = (this || _global).fields[i];\n\n      if (requiredMatches[field]) {\n        allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field]);\n      }\n\n      if (prohibitedMatches[field]) {\n        allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field]);\n      }\n    }\n\n    var matchingFieldRefs = Object.keys(matchingFields),\n        results = [],\n        matches = Object.create(null);\n    /*\n     * If the query is negated (contains only prohibited terms)\n     * we need to get _all_ fieldRefs currently existing in the\n     * index. This is only done when we know that the query is\n     * entirely prohibited terms to avoid any cost of getting all\n     * fieldRefs unnecessarily.\n     *\n     * Additionally, blank MatchData must be created to correctly\n     * populate the results.\n     */\n\n    if (query.isNegated()) {\n      matchingFieldRefs = Object.keys((this || _global).fieldVectors);\n\n      for (var i = 0; i < matchingFieldRefs.length; i++) {\n        var matchingFieldRef = matchingFieldRefs[i];\n        var fieldRef = lunr.FieldRef.fromString(matchingFieldRef);\n        matchingFields[matchingFieldRef] = new lunr.MatchData();\n      }\n    }\n\n    for (var i = 0; i < matchingFieldRefs.length; i++) {\n      /*\n       * Currently we have document fields that match the query, but we\n       * need to return documents. The matchData and scores are combined\n       * from multiple fields belonging to the same document.\n       *\n       * Scores are calculated by field, using the query vectors created\n       * above, and combined into a final document score using addition.\n       */\n      var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]),\n          docRef = fieldRef.docRef;\n\n      if (!allRequiredMatches.contains(docRef)) {\n        continue;\n      }\n\n      if (allProhibitedMatches.contains(docRef)) {\n        continue;\n      }\n\n      var fieldVector = (this || _global).fieldVectors[fieldRef],\n          score = queryVectors[fieldRef.fieldName].similarity(fieldVector),\n          docMatch;\n\n      if ((docMatch = matches[docRef]) !== undefined) {\n        docMatch.score += score;\n        docMatch.matchData.combine(matchingFields[fieldRef]);\n      } else {\n        var match = {\n          ref: docRef,\n          score: score,\n          matchData: matchingFields[fieldRef]\n        };\n        matches[docRef] = match;\n        results.push(match);\n      }\n    }\n    /*\n     * Sort the results objects by score, highest first.\n     */\n\n\n    return results.sort(function (a, b) {\n      return b.score - a.score;\n    });\n  };\n  /**\n   * Prepares the index for JSON serialization.\n   *\n   * The schema for this JSON blob will be described in a\n   * separate JSON schema file.\n   *\n   * @returns {Object}\n   */\n\n\n  lunr.Index.prototype.toJSON = function () {\n    var invertedIndex = Object.keys((this || _global).invertedIndex).sort().map(function (term) {\n      return [term, (this || _global).invertedIndex[term]];\n    }, this || _global);\n    var fieldVectors = Object.keys((this || _global).fieldVectors).map(function (ref) {\n      return [ref, (this || _global).fieldVectors[ref].toJSON()];\n    }, this || _global);\n    return {\n      version: lunr.version,\n      fields: (this || _global).fields,\n      fieldVectors: fieldVectors,\n      invertedIndex: invertedIndex,\n      pipeline: (this || _global).pipeline.toJSON()\n    };\n  };\n  /**\n   * Loads a previously serialized lunr.Index\n   *\n   * @param {Object} serializedIndex - A previously serialized lunr.Index\n   * @returns {lunr.Index}\n   */\n\n\n  lunr.Index.load = function (serializedIndex) {\n    var attrs = {},\n        fieldVectors = {},\n        serializedVectors = serializedIndex.fieldVectors,\n        invertedIndex = Object.create(null),\n        serializedInvertedIndex = serializedIndex.invertedIndex,\n        tokenSetBuilder = new lunr.TokenSet.Builder(),\n        pipeline = lunr.Pipeline.load(serializedIndex.pipeline);\n\n    if (serializedIndex.version != lunr.version) {\n      lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\");\n    }\n\n    for (var i = 0; i < serializedVectors.length; i++) {\n      var tuple = serializedVectors[i],\n          ref = tuple[0],\n          elements = tuple[1];\n      fieldVectors[ref] = new lunr.Vector(elements);\n    }\n\n    for (var i = 0; i < serializedInvertedIndex.length; i++) {\n      var tuple = serializedInvertedIndex[i],\n          term = tuple[0],\n          posting = tuple[1];\n      tokenSetBuilder.insert(term);\n      invertedIndex[term] = posting;\n    }\n\n    tokenSetBuilder.finish();\n    attrs.fields = serializedIndex.fields;\n    attrs.fieldVectors = fieldVectors;\n    attrs.invertedIndex = invertedIndex;\n    attrs.tokenSet = tokenSetBuilder.root;\n    attrs.pipeline = pipeline;\n    return new lunr.Index(attrs);\n  };\n  /*!\n   * lunr.Builder\n   * Copyright (C) 2020 Oliver Nightingale\n   */\n\n  /**\n   * lunr.Builder performs indexing on a set of documents and\n   * returns instances of lunr.Index ready for querying.\n   *\n   * All configuration of the index is done via the builder, the\n   * fields to index, the document reference, the text processing\n   * pipeline and document scoring parameters are all set on the\n   * builder before indexing.\n   *\n   * @constructor\n   * @property {string} _ref - Internal reference to the document reference field.\n   * @property {string[]} _fields - Internal reference to the document fields to index.\n   * @property {object} invertedIndex - The inverted index maps terms to document fields.\n   * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\n   * @property {object} documentLengths - Keeps track of the length of documents added to the index.\n   * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\n   * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\n   * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\n   * @property {number} documentCount - Keeps track of the total number of documents indexed.\n   * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\n   * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\n   * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\n   * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\n   */\n\n\n  lunr.Builder = function () {\n    (this || _global)._ref = \"id\";\n    (this || _global)._fields = Object.create(null);\n    (this || _global)._documents = Object.create(null);\n    (this || _global).invertedIndex = Object.create(null);\n    (this || _global).fieldTermFrequencies = {};\n    (this || _global).fieldLengths = {};\n    (this || _global).tokenizer = lunr.tokenizer;\n    (this || _global).pipeline = new lunr.Pipeline();\n    (this || _global).searchPipeline = new lunr.Pipeline();\n    (this || _global).documentCount = 0;\n    (this || _global)._b = 0.75;\n    (this || _global)._k1 = 1.2;\n    (this || _global).termIndex = 0;\n    (this || _global).metadataWhitelist = [];\n  };\n  /**\n   * Sets the document field used as the document reference. Every document must have this field.\n   * The type of this field in the document should be a string, if it is not a string it will be\n   * coerced into a string by calling toString.\n   *\n   * The default ref is 'id'.\n   *\n   * The ref should _not_ be changed during indexing, it should be set before any documents are\n   * added to the index. Changing it during indexing can lead to inconsistent results.\n   *\n   * @param {string} ref - The name of the reference field in the document.\n   */\n\n\n  lunr.Builder.prototype.ref = function (ref) {\n    (this || _global)._ref = ref;\n  };\n  /**\n   * A function that is used to extract a field from a document.\n   *\n   * Lunr expects a field to be at the top level of a document, if however the field\n   * is deeply nested within a document an extractor function can be used to extract\n   * the right field for indexing.\n   *\n   * @callback fieldExtractor\n   * @param {object} doc - The document being added to the index.\n   * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\n   * @example <caption>Extracting a nested field</caption>\n   * function (doc) { return doc.nested.field }\n   */\n\n  /**\n   * Adds a field to the list of document fields that will be indexed. Every document being\n   * indexed should have this field. Null values for this field in indexed documents will\n   * not cause errors but will limit the chance of that document being retrieved by searches.\n   *\n   * All fields should be added before adding documents to the index. Adding fields after\n   * a document has been indexed will have no effect on already indexed documents.\n   *\n   * Fields can be boosted at build time. This allows terms within that field to have more\n   * importance when ranking search results. Use a field boost to specify that matches within\n   * one field are more important than other fields.\n   *\n   * @param {string} fieldName - The name of a field to index in all documents.\n   * @param {object} attributes - Optional attributes associated with this field.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\n   * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\n   * @throws {RangeError} fieldName cannot contain unsupported characters '/'\n   */\n\n\n  lunr.Builder.prototype.field = function (fieldName, attributes) {\n    if (/\\//.test(fieldName)) {\n      throw new RangeError(\"Field '\" + fieldName + \"' contains illegal character '/'\");\n    }\n\n    (this || _global)._fields[fieldName] = attributes || {};\n  };\n  /**\n   * A parameter to tune the amount of field length normalisation that is applied when\n   * calculating relevance scores. A value of 0 will completely disable any normalisation\n   * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\n   * will be clamped to the range 0 - 1.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n\n\n  lunr.Builder.prototype.b = function (number) {\n    if (number < 0) {\n      (this || _global)._b = 0;\n    } else if (number > 1) {\n      (this || _global)._b = 1;\n    } else {\n      (this || _global)._b = number;\n    }\n  };\n  /**\n   * A parameter that controls the speed at which a rise in term frequency results in term\n   * frequency saturation. The default value is 1.2. Setting this to a higher value will give\n   * slower saturation levels, a lower value will result in quicker saturation.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n\n\n  lunr.Builder.prototype.k1 = function (number) {\n    (this || _global)._k1 = number;\n  };\n  /**\n   * Adds a document to the index.\n   *\n   * Before adding fields to the index the index should have been fully setup, with the document\n   * ref and all fields to index already having been specified.\n   *\n   * The document must have a field name as specified by the ref (by default this is 'id') and\n   * it should have all fields defined for indexing, though null or undefined values will not\n   * cause errors.\n   *\n   * Entire documents can be boosted at build time. Applying a boost to a document indicates that\n   * this document should rank higher in search results than other documents.\n   *\n   * @param {object} doc - The document to add to the index.\n   * @param {object} attributes - Optional attributes associated with this document.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\n   */\n\n\n  lunr.Builder.prototype.add = function (doc, attributes) {\n    var docRef = doc[(this || _global)._ref],\n        fields = Object.keys((this || _global)._fields);\n    (this || _global)._documents[docRef] = attributes || {};\n    (this || _global).documentCount += 1;\n\n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i],\n          extractor = (this || _global)._fields[fieldName].extractor,\n          field = extractor ? extractor(doc) : doc[fieldName],\n          tokens = this.tokenizer(field, {\n        fields: [fieldName]\n      }),\n          terms = (this || _global).pipeline.run(tokens),\n          fieldRef = new lunr.FieldRef(docRef, fieldName),\n          fieldTerms = Object.create(null);\n\n      (this || _global).fieldTermFrequencies[fieldRef] = fieldTerms;\n      (this || _global).fieldLengths[fieldRef] = 0; // store the length of this field for this document\n\n      (this || _global).fieldLengths[fieldRef] += terms.length; // calculate term frequencies for this field\n\n      for (var j = 0; j < terms.length; j++) {\n        var term = terms[j];\n\n        if (fieldTerms[term] == undefined) {\n          fieldTerms[term] = 0;\n        }\n\n        fieldTerms[term] += 1; // add to inverted index\n        // create an initial posting if one doesn't exist\n\n        if ((this || _global).invertedIndex[term] == undefined) {\n          var posting = Object.create(null);\n          posting[\"_index\"] = (this || _global).termIndex;\n          (this || _global).termIndex += 1;\n\n          for (var k = 0; k < fields.length; k++) {\n            posting[fields[k]] = Object.create(null);\n          }\n\n          (this || _global).invertedIndex[term] = posting;\n        } // add an entry for this term/fieldName/docRef to the invertedIndex\n\n\n        if ((this || _global).invertedIndex[term][fieldName][docRef] == undefined) {\n          (this || _global).invertedIndex[term][fieldName][docRef] = Object.create(null);\n        } // store all whitelisted metadata about this token in the\n        // inverted index\n\n\n        for (var l = 0; l < (this || _global).metadataWhitelist.length; l++) {\n          var metadataKey = (this || _global).metadataWhitelist[l],\n              metadata = term.metadata[metadataKey];\n\n          if ((this || _global).invertedIndex[term][fieldName][docRef][metadataKey] == undefined) {\n            (this || _global).invertedIndex[term][fieldName][docRef][metadataKey] = [];\n          }\n\n          (this || _global).invertedIndex[term][fieldName][docRef][metadataKey].push(metadata);\n        }\n      }\n    }\n  };\n  /**\n   * Calculates the average document length for this index\n   *\n   * @private\n   */\n\n\n  lunr.Builder.prototype.calculateAverageFieldLengths = function () {\n    var fieldRefs = Object.keys((this || _global).fieldLengths),\n        numberOfFields = fieldRefs.length,\n        accumulator = {},\n        documentsWithField = {};\n\n    for (var i = 0; i < numberOfFields; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          field = fieldRef.fieldName;\n      documentsWithField[field] || (documentsWithField[field] = 0);\n      documentsWithField[field] += 1;\n      accumulator[field] || (accumulator[field] = 0);\n      accumulator[field] += (this || _global).fieldLengths[fieldRef];\n    }\n\n    var fields = Object.keys((this || _global)._fields);\n\n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i];\n      accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName];\n    }\n\n    (this || _global).averageFieldLength = accumulator;\n  };\n  /**\n   * Builds a vector space model of every document using lunr.Vector\n   *\n   * @private\n   */\n\n\n  lunr.Builder.prototype.createFieldVectors = function () {\n    var fieldVectors = {},\n        fieldRefs = Object.keys((this || _global).fieldTermFrequencies),\n        fieldRefsLength = fieldRefs.length,\n        termIdfCache = Object.create(null);\n\n    for (var i = 0; i < fieldRefsLength; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          fieldName = fieldRef.fieldName,\n          fieldLength = (this || _global).fieldLengths[fieldRef],\n          fieldVector = new lunr.Vector(),\n          termFrequencies = (this || _global).fieldTermFrequencies[fieldRef],\n          terms = Object.keys(termFrequencies),\n          termsLength = terms.length;\n      var fieldBoost = (this || _global)._fields[fieldName].boost || 1,\n          docBoost = (this || _global)._documents[fieldRef.docRef].boost || 1;\n\n      for (var j = 0; j < termsLength; j++) {\n        var term = terms[j],\n            tf = termFrequencies[term],\n            termIndex = (this || _global).invertedIndex[term]._index,\n            idf,\n            score,\n            scoreWithPrecision;\n\n        if (termIdfCache[term] === undefined) {\n          idf = lunr.idf((this || _global).invertedIndex[term], (this || _global).documentCount);\n          termIdfCache[term] = idf;\n        } else {\n          idf = termIdfCache[term];\n        }\n\n        score = idf * (((this || _global)._k1 + 1) * tf) / ((this || _global)._k1 * (1 - (this || _global)._b + (this || _global)._b * (fieldLength / (this || _global).averageFieldLength[fieldName])) + tf);\n        score *= fieldBoost;\n        score *= docBoost;\n        scoreWithPrecision = Math.round(score * 1000) / 1000; // Converts 1.23456789 to 1.234.\n        // Reducing the precision so that the vectors take up less\n        // space when serialised. Doing it now so that they behave\n        // the same before and after serialisation. Also, this is\n        // the fastest approach to reducing a number's precision in\n        // JavaScript.\n\n        fieldVector.insert(termIndex, scoreWithPrecision);\n      }\n\n      fieldVectors[fieldRef] = fieldVector;\n    }\n\n    (this || _global).fieldVectors = fieldVectors;\n  };\n  /**\n   * Creates a token set of all tokens in the index using lunr.TokenSet\n   *\n   * @private\n   */\n\n\n  lunr.Builder.prototype.createTokenSet = function () {\n    (this || _global).tokenSet = lunr.TokenSet.fromArray(Object.keys((this || _global).invertedIndex).sort());\n  };\n  /**\n   * Builds the index, creating an instance of lunr.Index.\n   *\n   * This completes the indexing process and should only be called\n   * once all documents have been added to the index.\n   *\n   * @returns {lunr.Index}\n   */\n\n\n  lunr.Builder.prototype.build = function () {\n    this.calculateAverageFieldLengths();\n    this.createFieldVectors();\n    this.createTokenSet();\n    return new lunr.Index({\n      invertedIndex: (this || _global).invertedIndex,\n      fieldVectors: (this || _global).fieldVectors,\n      tokenSet: (this || _global).tokenSet,\n      fields: Object.keys((this || _global)._fields),\n      pipeline: (this || _global).searchPipeline\n    });\n  };\n  /**\n   * Applies a plugin to the index builder.\n   *\n   * A plugin is a function that is called with the index builder as its context.\n   * Plugins can be used to customise or extend the behaviour of the index\n   * in some way. A plugin is just a function, that encapsulated the custom\n   * behaviour that should be applied when building the index.\n   *\n   * The plugin function will be called with the index builder as its argument, additional\n   * arguments can also be passed when calling use. The function will be called\n   * with the index builder as its context.\n   *\n   * @param {Function} plugin The plugin to apply.\n   */\n\n\n  lunr.Builder.prototype.use = function (fn) {\n    var args = Array.prototype.slice.call(arguments, 1);\n    args.unshift(this || _global);\n    fn.apply(this || _global, args);\n  };\n  /**\n   * Contains and collects metadata about a matching document.\n   * A single instance of lunr.MatchData is returned as part of every\n   * lunr.Index~Result.\n   *\n   * @constructor\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   * @property {object} metadata - A cloned collection of metadata associated with this document.\n   * @see {@link lunr.Index~Result}\n   */\n\n\n  lunr.MatchData = function (term, field, metadata) {\n    var clonedMetadata = Object.create(null),\n        metadataKeys = Object.keys(metadata || {}); // Cloning the metadata to prevent the original\n    // being mutated during match data combination.\n    // Metadata is kept in an array within the inverted\n    // index so cloning the data can be done with\n    // Array#slice\n\n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i];\n      clonedMetadata[key] = metadata[key].slice();\n    }\n\n    (this || _global).metadata = Object.create(null);\n\n    if (term !== undefined) {\n      (this || _global).metadata[term] = Object.create(null);\n      (this || _global).metadata[term][field] = clonedMetadata;\n    }\n  };\n  /**\n   * An instance of lunr.MatchData will be created for every term that matches a\n   * document. However only one instance is required in a lunr.Index~Result. This\n   * method combines metadata from another instance of lunr.MatchData with this\n   * objects metadata.\n   *\n   * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\n   * @see {@link lunr.Index~Result}\n   */\n\n\n  lunr.MatchData.prototype.combine = function (otherMatchData) {\n    var terms = Object.keys(otherMatchData.metadata);\n\n    for (var i = 0; i < terms.length; i++) {\n      var term = terms[i],\n          fields = Object.keys(otherMatchData.metadata[term]);\n\n      if ((this || _global).metadata[term] == undefined) {\n        (this || _global).metadata[term] = Object.create(null);\n      }\n\n      for (var j = 0; j < fields.length; j++) {\n        var field = fields[j],\n            keys = Object.keys(otherMatchData.metadata[term][field]);\n\n        if ((this || _global).metadata[term][field] == undefined) {\n          (this || _global).metadata[term][field] = Object.create(null);\n        }\n\n        for (var k = 0; k < keys.length; k++) {\n          var key = keys[k];\n\n          if ((this || _global).metadata[term][field][key] == undefined) {\n            (this || _global).metadata[term][field][key] = otherMatchData.metadata[term][field][key];\n          } else {\n            (this || _global).metadata[term][field][key] = (this || _global).metadata[term][field][key].concat(otherMatchData.metadata[term][field][key]);\n          }\n        }\n      }\n    }\n  };\n  /**\n   * Add metadata for a term/field pair to this instance of match data.\n   *\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   */\n\n\n  lunr.MatchData.prototype.add = function (term, field, metadata) {\n    if (!(term in (this || _global).metadata)) {\n      (this || _global).metadata[term] = Object.create(null);\n      (this || _global).metadata[term][field] = metadata;\n      return;\n    }\n\n    if (!(field in (this || _global).metadata[term])) {\n      (this || _global).metadata[term][field] = metadata;\n      return;\n    }\n\n    var metadataKeys = Object.keys(metadata);\n\n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i];\n\n      if (key in (this || _global).metadata[term][field]) {\n        (this || _global).metadata[term][field][key] = (this || _global).metadata[term][field][key].concat(metadata[key]);\n      } else {\n        (this || _global).metadata[term][field][key] = metadata[key];\n      }\n    }\n  };\n  /**\n   * A lunr.Query provides a programmatic way of defining queries to be performed\n   * against a {@link lunr.Index}.\n   *\n   * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\n   * so the query object is pre-initialized with the right index fields.\n   *\n   * @constructor\n   * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\n   * @property {string[]} allFields - An array of all available fields in a lunr.Index.\n   */\n\n\n  lunr.Query = function (allFields) {\n    (this || _global).clauses = [];\n    (this || _global).allFields = allFields;\n  };\n  /**\n   * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\n   *\n   * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\n   * concatenation.\n   *\n   * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\n   *\n   * @constant\n   * @default\n   * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\n   * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\n   * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with trailing wildcard</caption>\n   * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\n   * @example <caption>query term with leading and trailing wildcard</caption>\n   * query.term('foo', {\n   *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\n   * })\n   */\n\n\n  lunr.Query.wildcard = new String(\"*\");\n  lunr.Query.wildcard.NONE = 0;\n  lunr.Query.wildcard.LEADING = 1;\n  lunr.Query.wildcard.TRAILING = 2;\n  /**\n   * Constants for indicating what kind of presence a term must have in matching documents.\n   *\n   * @constant\n   * @enum {number}\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with required presence</caption>\n   * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\n   */\n\n  lunr.Query.presence = {\n    /**\n     * Term's presence in a document is optional, this is the default value.\n     */\n    OPTIONAL: 1,\n\n    /**\n     * Term's presence in a document is required, documents that do not contain\n     * this term will not be returned.\n     */\n    REQUIRED: 2,\n\n    /**\n     * Term's presence in a document is prohibited, documents that do contain\n     * this term will not be returned.\n     */\n    PROHIBITED: 3\n  };\n  /**\n   * A single clause in a {@link lunr.Query} contains a term and details on how to\n   * match that term against a {@link lunr.Index}.\n   *\n   * @typedef {Object} lunr.Query~Clause\n   * @property {string[]} fields - The fields in an index this clause should be matched against.\n   * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\n   * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\n   * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\n   * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\n   * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\n   */\n\n  /**\n   * Adds a {@link lunr.Query~Clause} to this query.\n   *\n   * Unless the clause contains the fields to be matched all fields will be matched. In addition\n   * a default boost of 1 is applied to the clause.\n   *\n   * @param {lunr.Query~Clause} clause - The clause to add to this query.\n   * @see lunr.Query~Clause\n   * @returns {lunr.Query}\n   */\n\n  lunr.Query.prototype.clause = function (clause) {\n    if (!(\"fields\" in clause)) {\n      clause.fields = (this || _global).allFields;\n    }\n\n    if (!(\"boost\" in clause)) {\n      clause.boost = 1;\n    }\n\n    if (!(\"usePipeline\" in clause)) {\n      clause.usePipeline = true;\n    }\n\n    if (!(\"wildcard\" in clause)) {\n      clause.wildcard = lunr.Query.wildcard.NONE;\n    }\n\n    if (clause.wildcard & lunr.Query.wildcard.LEADING && clause.term.charAt(0) != lunr.Query.wildcard) {\n      clause.term = \"*\" + clause.term;\n    }\n\n    if (clause.wildcard & lunr.Query.wildcard.TRAILING && clause.term.slice(-1) != lunr.Query.wildcard) {\n      clause.term = \"\" + clause.term + \"*\";\n    }\n\n    if (!(\"presence\" in clause)) {\n      clause.presence = lunr.Query.presence.OPTIONAL;\n    }\n\n    (this || _global).clauses.push(clause);\n\n    return this || _global;\n  };\n  /**\n   * A negated query is one in which every clause has a presence of\n   * prohibited. These queries require some special processing to return\n   * the expected results.\n   *\n   * @returns boolean\n   */\n\n\n  lunr.Query.prototype.isNegated = function () {\n    for (var i = 0; i < (this || _global).clauses.length; i++) {\n      if ((this || _global).clauses[i].presence != lunr.Query.presence.PROHIBITED) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n  /**\n   * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\n   * to the list of clauses that make up this query.\n   *\n   * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\n   * to a token or token-like string should be done before calling this method.\n   *\n   * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\n   * array, each term in the array will share the same options.\n   *\n   * @param {object|object[]} term - The term(s) to add to the query.\n   * @param {object} [options] - Any additional properties to add to the query clause.\n   * @returns {lunr.Query}\n   * @see lunr.Query#clause\n   * @see lunr.Query~Clause\n   * @example <caption>adding a single term to a query</caption>\n   * query.term(\"foo\")\n   * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\n   * query.term(\"foo\", {\n   *   fields: [\"title\"],\n   *   boost: 10,\n   *   wildcard: lunr.Query.wildcard.TRAILING\n   * })\n   * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\n   * query.term(lunr.tokenizer(\"foo bar\"))\n   */\n\n\n  lunr.Query.prototype.term = function (term, options) {\n    if (Array.isArray(term)) {\n      term.forEach(function (t) {\n        this.term(t, lunr.utils.clone(options));\n      }, this || _global);\n      return this || _global;\n    }\n\n    var clause = options || {};\n    clause.term = term.toString();\n    this.clause(clause);\n    return this || _global;\n  };\n\n  lunr.QueryParseError = function (message, start, end) {\n    (this || _global).name = \"QueryParseError\";\n    (this || _global).message = message;\n    (this || _global).start = start;\n    (this || _global).end = end;\n  };\n\n  lunr.QueryParseError.prototype = new Error();\n\n  lunr.QueryLexer = function (str) {\n    (this || _global).lexemes = [];\n    (this || _global).str = str;\n    (this || _global).length = str.length;\n    (this || _global).pos = 0;\n    (this || _global).start = 0;\n    (this || _global).escapeCharPositions = [];\n  };\n\n  lunr.QueryLexer.prototype.run = function () {\n    var state = lunr.QueryLexer.lexText;\n\n    while (state) {\n      state = state(this || _global);\n    }\n  };\n\n  lunr.QueryLexer.prototype.sliceString = function () {\n    var subSlices = [],\n        sliceStart = (this || _global).start,\n        sliceEnd = (this || _global).pos;\n\n    for (var i = 0; i < (this || _global).escapeCharPositions.length; i++) {\n      sliceEnd = (this || _global).escapeCharPositions[i];\n      subSlices.push((this || _global).str.slice(sliceStart, sliceEnd));\n      sliceStart = sliceEnd + 1;\n    }\n\n    subSlices.push((this || _global).str.slice(sliceStart, (this || _global).pos));\n    (this || _global).escapeCharPositions.length = 0;\n    return subSlices.join(\"\");\n  };\n\n  lunr.QueryLexer.prototype.emit = function (type) {\n    (this || _global).lexemes.push({\n      type: type,\n      str: this.sliceString(),\n      start: (this || _global).start,\n      end: (this || _global).pos\n    });\n\n    (this || _global).start = (this || _global).pos;\n  };\n\n  lunr.QueryLexer.prototype.escapeCharacter = function () {\n    (this || _global).escapeCharPositions.push((this || _global).pos - 1);\n\n    (this || _global).pos += 1;\n  };\n\n  lunr.QueryLexer.prototype.next = function () {\n    if ((this || _global).pos >= (this || _global).length) {\n      return lunr.QueryLexer.EOS;\n    }\n\n    var char = (this || _global).str.charAt((this || _global).pos);\n\n    (this || _global).pos += 1;\n    return char;\n  };\n\n  lunr.QueryLexer.prototype.width = function () {\n    return (this || _global).pos - (this || _global).start;\n  };\n\n  lunr.QueryLexer.prototype.ignore = function () {\n    if ((this || _global).start == (this || _global).pos) {\n      (this || _global).pos += 1;\n    }\n\n    (this || _global).start = (this || _global).pos;\n  };\n\n  lunr.QueryLexer.prototype.backup = function () {\n    (this || _global).pos -= 1;\n  };\n\n  lunr.QueryLexer.prototype.acceptDigitRun = function () {\n    var char, charCode;\n\n    do {\n      char = this.next();\n      charCode = char.charCodeAt(0);\n    } while (charCode > 47 && charCode < 58);\n\n    if (char != lunr.QueryLexer.EOS) {\n      this.backup();\n    }\n  };\n\n  lunr.QueryLexer.prototype.more = function () {\n    return (this || _global).pos < (this || _global).length;\n  };\n\n  lunr.QueryLexer.EOS = \"EOS\";\n  lunr.QueryLexer.FIELD = \"FIELD\";\n  lunr.QueryLexer.TERM = \"TERM\";\n  lunr.QueryLexer.EDIT_DISTANCE = \"EDIT_DISTANCE\";\n  lunr.QueryLexer.BOOST = \"BOOST\";\n  lunr.QueryLexer.PRESENCE = \"PRESENCE\";\n\n  lunr.QueryLexer.lexField = function (lexer) {\n    lexer.backup();\n    lexer.emit(lunr.QueryLexer.FIELD);\n    lexer.ignore();\n    return lunr.QueryLexer.lexText;\n  };\n\n  lunr.QueryLexer.lexTerm = function (lexer) {\n    if (lexer.width() > 1) {\n      lexer.backup();\n      lexer.emit(lunr.QueryLexer.TERM);\n    }\n\n    lexer.ignore();\n\n    if (lexer.more()) {\n      return lunr.QueryLexer.lexText;\n    }\n  };\n\n  lunr.QueryLexer.lexEditDistance = function (lexer) {\n    lexer.ignore();\n    lexer.acceptDigitRun();\n    lexer.emit(lunr.QueryLexer.EDIT_DISTANCE);\n    return lunr.QueryLexer.lexText;\n  };\n\n  lunr.QueryLexer.lexBoost = function (lexer) {\n    lexer.ignore();\n    lexer.acceptDigitRun();\n    lexer.emit(lunr.QueryLexer.BOOST);\n    return lunr.QueryLexer.lexText;\n  };\n\n  lunr.QueryLexer.lexEOS = function (lexer) {\n    if (lexer.width() > 0) {\n      lexer.emit(lunr.QueryLexer.TERM);\n    }\n  }; // This matches the separator used when tokenising fields\n  // within a document. These should match otherwise it is\n  // not possible to search for some tokens within a document.\n  //\n  // It is possible for the user to change the separator on the\n  // tokenizer so it _might_ clash with any other of the special\n  // characters already used within the search string, e.g. :.\n  //\n  // This means that it is possible to change the separator in\n  // such a way that makes some words unsearchable using a search\n  // string.\n\n\n  lunr.QueryLexer.termSeparator = lunr.tokenizer.separator;\n\n  lunr.QueryLexer.lexText = function (lexer) {\n    while (true) {\n      var char = lexer.next();\n\n      if (char == lunr.QueryLexer.EOS) {\n        return lunr.QueryLexer.lexEOS;\n      } // Escape character is '\\'\n\n\n      if (char.charCodeAt(0) == 92) {\n        lexer.escapeCharacter();\n        continue;\n      }\n\n      if (char == \":\") {\n        return lunr.QueryLexer.lexField;\n      }\n\n      if (char == \"~\") {\n        lexer.backup();\n\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM);\n        }\n\n        return lunr.QueryLexer.lexEditDistance;\n      }\n\n      if (char == \"^\") {\n        lexer.backup();\n\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM);\n        }\n\n        return lunr.QueryLexer.lexBoost;\n      } // \"+\" indicates term presence is required\n      // checking for length to ensure that only\n      // leading \"+\" are considered\n\n\n      if (char == \"+\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE);\n        return lunr.QueryLexer.lexText;\n      } // \"-\" indicates term presence is prohibited\n      // checking for length to ensure that only\n      // leading \"-\" are considered\n\n\n      if (char == \"-\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE);\n        return lunr.QueryLexer.lexText;\n      }\n\n      if (char.match(lunr.QueryLexer.termSeparator)) {\n        return lunr.QueryLexer.lexTerm;\n      }\n    }\n  };\n\n  lunr.QueryParser = function (str, query) {\n    (this || _global).lexer = new lunr.QueryLexer(str);\n    (this || _global).query = query;\n    (this || _global).currentClause = {};\n    (this || _global).lexemeIdx = 0;\n  };\n\n  lunr.QueryParser.prototype.parse = function () {\n    (this || _global).lexer.run();\n\n    (this || _global).lexemes = (this || _global).lexer.lexemes;\n    var state = lunr.QueryParser.parseClause;\n\n    while (state) {\n      state = state(this || _global);\n    }\n\n    return (this || _global).query;\n  };\n\n  lunr.QueryParser.prototype.peekLexeme = function () {\n    return (this || _global).lexemes[(this || _global).lexemeIdx];\n  };\n\n  lunr.QueryParser.prototype.consumeLexeme = function () {\n    var lexeme = this.peekLexeme();\n    (this || _global).lexemeIdx += 1;\n    return lexeme;\n  };\n\n  lunr.QueryParser.prototype.nextClause = function () {\n    var completedClause = (this || _global).currentClause;\n\n    (this || _global).query.clause(completedClause);\n\n    (this || _global).currentClause = {};\n  };\n\n  lunr.QueryParser.parseClause = function (parser) {\n    var lexeme = parser.peekLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    switch (lexeme.type) {\n      case lunr.QueryLexer.PRESENCE:\n        return lunr.QueryParser.parsePresence;\n\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField;\n\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm;\n\n      default:\n        var errorMessage = \"expected either a field or a term, found \" + lexeme.type;\n\n        if (lexeme.str.length >= 1) {\n          errorMessage += \" with value '\" + lexeme.str + \"'\";\n        }\n\n        throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n  };\n\n  lunr.QueryParser.parsePresence = function (parser) {\n    var lexeme = parser.consumeLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    switch (lexeme.str) {\n      case \"-\":\n        parser.currentClause.presence = lunr.Query.presence.PROHIBITED;\n        break;\n\n      case \"+\":\n        parser.currentClause.presence = lunr.Query.presence.REQUIRED;\n        break;\n\n      default:\n        var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\";\n        throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    var nextLexeme = parser.peekLexeme();\n\n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term or field, found nothing\";\n      throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField;\n\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm;\n\n      default:\n        var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\";\n        throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n    }\n  };\n\n  lunr.QueryParser.parseField = function (parser) {\n    var lexeme = parser.consumeLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    if (parser.query.allFields.indexOf(lexeme.str) == -1) {\n      var possibleFields = parser.query.allFields.map(function (f) {\n        return \"'\" + f + \"'\";\n      }).join(\", \"),\n          errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields;\n      throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    parser.currentClause.fields = [lexeme.str];\n    var nextLexeme = parser.peekLexeme();\n\n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term, found nothing\";\n      throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm;\n\n      default:\n        var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\";\n        throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n    }\n  };\n\n  lunr.QueryParser.parseTerm = function (parser) {\n    var lexeme = parser.consumeLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    parser.currentClause.term = lexeme.str.toLowerCase();\n\n    if (lexeme.str.indexOf(\"*\") != -1) {\n      parser.currentClause.usePipeline = false;\n    }\n\n    var nextLexeme = parser.peekLexeme();\n\n    if (nextLexeme == undefined) {\n      parser.nextClause();\n      return;\n    }\n\n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause();\n        return lunr.QueryParser.parseTerm;\n\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause();\n        return lunr.QueryParser.parseField;\n\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance;\n\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost;\n\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause();\n        return lunr.QueryParser.parsePresence;\n\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n        throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n    }\n  };\n\n  lunr.QueryParser.parseEditDistance = function (parser) {\n    var lexeme = parser.consumeLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    var editDistance = parseInt(lexeme.str, 10);\n\n    if (isNaN(editDistance)) {\n      var errorMessage = \"edit distance must be numeric\";\n      throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    parser.currentClause.editDistance = editDistance;\n    var nextLexeme = parser.peekLexeme();\n\n    if (nextLexeme == undefined) {\n      parser.nextClause();\n      return;\n    }\n\n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause();\n        return lunr.QueryParser.parseTerm;\n\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause();\n        return lunr.QueryParser.parseField;\n\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance;\n\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost;\n\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause();\n        return lunr.QueryParser.parsePresence;\n\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n        throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n    }\n  };\n\n  lunr.QueryParser.parseBoost = function (parser) {\n    var lexeme = parser.consumeLexeme();\n\n    if (lexeme == undefined) {\n      return;\n    }\n\n    var boost = parseInt(lexeme.str, 10);\n\n    if (isNaN(boost)) {\n      var errorMessage = \"boost must be numeric\";\n      throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n    }\n\n    parser.currentClause.boost = boost;\n    var nextLexeme = parser.peekLexeme();\n\n    if (nextLexeme == undefined) {\n      parser.nextClause();\n      return;\n    }\n\n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause();\n        return lunr.QueryParser.parseTerm;\n\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause();\n        return lunr.QueryParser.parseField;\n\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance;\n\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost;\n\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause();\n        return lunr.QueryParser.parsePresence;\n\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n        throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n    }\n  }\n  /**\n   * export the module via AMD, CommonJS or as a browser global\n   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n   */\n  ;\n\n  (function (root, factory) {\n    /**\n     * Node. Does not work with strict CommonJS, but\n     * only CommonJS-like enviroments that support module.exports,\n     * like Node.\n     */\n    exports = factory();\n  })(this || _global, function () {\n    /**\n     * Just return a value to define the module export.\n     * This example returns an object, but the module\n     * can return a function as the exported value.\n     */\n    return lunr;\n  });\n})();\n\nexport default exports;"],"names":["_global","globalThis","self","global","exports","lunr","config","builder","Builder","pipeline","add","trimmer","stopWordFilter","stemmer","searchPipeline","call","build","version","utils","warn","message","console","this","asString","obj","toString","clone","undefined","Object","create","keys","i","length","key","val","Array","isArray","slice","TypeError","FieldRef","docRef","fieldName","stringValue","_stringValue","joiner","fromString","s","n","indexOf","fieldRef","prototype","Set","elements","complete","intersect","other","union","contains","empty","object","a","b","intersection","element","push","concat","idf","posting","documentCount","documentsWithTerm","x","Math","log","abs","Token","str","metadata","update","fn","tokenizer","map","t","toLowerCase","len","tokens","sliceEnd","sliceStart","char","charAt","sliceLength","match","separator","tokenMetadata","Pipeline","_stack","registeredFunctions","registerFunction","label","warnIfFunctionNotRegistered","isRegistered","load","serialised","forEach","fnName","Error","fns","arguments","after","existingFn","newFn","pos","splice","before","remove","run","stackLength","memo","j","result","k","runString","token","reset","toJSON","Vector","_magnitude","positionForIndex","index","start","end","pivotPoint","floor","pivotIndex","insert","insertIdx","upsert","position","magnitude","sumOfSquares","elementsLength","sqrt","dot","otherVector","dotProduct","aLen","bLen","aVal","bVal","similarity","toArray","output","step2list","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","step3list","icate","ative","alize","iciti","ical","ful","ness","c","v","C","V","mgr0","meq1","mgr1","s_v","re_mgr0","RegExp","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","substr","toUpperCase","test","replace","fp","exec","generateStopWordFilter","stopWords","words","reduce","stopWord","TokenSet","final","edges","id","_nextId","fromArray","arr","finish","root","fromClause","clause","fromFuzzyString","term","editDistance","stack","node","editsRemaining","frame","pop","noEditNode","insertionNode","substitutionNode","charA","charB","transposeNode","next","prefix","edge","_str","labels","sort","qNode","qEdges","qLen","nEdges","nLen","q","qEdge","nEdge","previousWord","uncheckedNodes","minimizedNodes","word","commonPrefix","minimize","child","nextNode","parent","downTo","childKey","Index","attrs","invertedIndex","fieldVectors","tokenSet","fields","search","queryString","query","parser","QueryParser","parse","Query","matchingFields","queryVectors","termFieldCache","requiredMatches","prohibitedMatches","clauses","terms","clauseMatches","usePipeline","m","termTokenSet","expandedTerms","presence","REQUIRED","field","expandedTerm","termIndex","_index","fieldPosting","matchingDocumentRefs","termField","matchingDocumentsSet","PROHIBITED","boost","l","matchingDocumentRef","matchingFieldRef","fieldMatch","MatchData","allRequiredMatches","allProhibitedMatches","matchingFieldRefs","results","matches","isNegated","fieldVector","score","docMatch","matchData","combine","ref","serializedIndex","serializedVectors","serializedInvertedIndex","tokenSetBuilder","tuple","_ref","_fields","_documents","fieldTermFrequencies","fieldLengths","_b","_k1","metadataWhitelist","attributes","RangeError","number","k1","doc","extractor","fieldTerms","metadataKey","calculateAverageFieldLengths","fieldRefs","numberOfFields","accumulator","documentsWithField","averageFieldLength","createFieldVectors","fieldRefsLength","termIdfCache","fieldLength","termFrequencies","termsLength","fieldBoost","docBoost","tf","scoreWithPrecision","round","createTokenSet","use","args","unshift","apply","clonedMetadata","metadataKeys","otherMatchData","allFields","wildcard","String","NONE","LEADING","TRAILING","OPTIONAL","options","QueryParseError","name","QueryLexer","lexemes","escapeCharPositions","state","lexText","sliceString","subSlices","join","emit","type","escapeCharacter","EOS","width","ignore","backup","acceptDigitRun","charCode","charCodeAt","more","FIELD","TERM","EDIT_DISTANCE","BOOST","PRESENCE","lexField","lexer","lexTerm","lexEditDistance","lexBoost","lexEOS","termSeparator","currentClause","lexemeIdx","parseClause","peekLexeme","consumeLexeme","lexeme","nextClause","completedClause","parsePresence","parseField","parseTerm","errorMessage","nextLexeme","possibleFields","f","parseEditDistance","parseBoost","parseInt","isNaN","factory"],"mappings":"AAAA,IAAIA,EAAgC,qBAAfC,WAA6BA,WAA6B,qBAATC,KAAuBA,KAAOC,OAEpG,IAAIC,EAAU;;;;;IASd,WAgCE,IAAIC,KAAO,SAAUC,GACnB,IAAIC,EAAU,IAAIF,KAAKG,QACvBD,EAAQE,SAASC,IAAIL,KAAKM,QAASN,KAAKO,eAAgBP,KAAKQ,SAC7DN,EAAQO,eAAeJ,IAAIL,KAAKQ,SAChCP,EAAOS,KAAKR,EAASA,GACrB,OAAOA,EAAQS,SAGjBX,KAAKY,QAAU,QAWfZ,KAAKa,MAAQ;;;;;;;KASbb,KAAKa,MAAMC,KAAO,SAAUhB,GAE1B,OAAO,SAAUiB,GACXjB,EAAOkB,SAAWA,QAAQF,MAC5BE,QAAQF,KAAKC,IAJD,CAQhBE,MAAQtB;;;;;;;;;;;KAcVK,KAAKa,MAAMK,SAAW,SAAUC,GAC9B,YAAiB,IAAbA,GAA0B,OAARA,EACb,GAEAA,EAAIC;;;;;;;;;;;;;;;;KAqBfpB,KAAKa,MAAMQ,MAAQ,SAAUF,GAC3B,GAAY,OAARA,QAAwBG,IAARH,EAClB,OAAOA,EAGT,IAAIE,EAAQE,OAAOC,OAAO,MACtBC,EAAOF,OAAOE,KAAKN,GAEvB,IAAK,IAAIO,EAAI,EAAGA,EAAID,EAAKE,OAAQD,IAAK,CACpC,IAAIE,EAAMH,EAAKC,GACXG,EAAMV,EAAIS,GAEd,GAAIE,MAAMC,QAAQF,GAChBR,EAAMO,GAAOC,EAAIG,YADnB,CAKA,GAAmB,kBAARH,GAAmC,kBAARA,GAAmC,mBAARA,EAKjE,MAAM,IAAII,UAAU,yDAJlBZ,EAAMO,GAAOC,GAOjB,OAAOR,GAGTrB,KAAKkC,SAAW,SAAUC,EAAQC,EAAWC,IAC1CpB,MAAQtB,GAASwC,OAASA,GAC1BlB,MAAQtB,GAASyC,UAAYA,GAC7BnB,MAAQtB,GAAS2C,aAAeD,GAGnCrC,KAAKkC,SAASK,OAAS,IAEvBvC,KAAKkC,SAASM,WAAa,SAAUC,GACnC,IAAIC,EAAID,EAAEE,QAAQ3C,KAAKkC,SAASK,QAEhC,IAAW,IAAPG,EACF,KAAM,6BAGR,IAAIE,EAAWH,EAAET,MAAM,EAAGU,GACtBP,EAASM,EAAET,MAAMU,EAAI,GACzB,OAAO,IAAI1C,KAAKkC,SAASC,EAAQS,EAAUH,IAG7CzC,KAAKkC,SAASW,UAAUzB,SAAW,gBACKE,IAAjCL,MAAQtB,GAAS2C,gBACnBrB,MAAQtB,GAAS2C,cAAgBrB,MAAQtB,GAASyC,UAAYpC,KAAKkC,SAASK,QAAUtB,MAAQtB,GAASwC,QAG1G,OAAQlB,MAAQtB,GAAS2C,cAc3BtC,KAAK8C,IAAM,SAAUC,IAClB9B,MAAQtB,GAASoD,SAAWxB,OAAOC,OAAO,MAE3C,GAAIuB,EAAU,EACX9B,MAAQtB,GAASgC,OAASoB,EAASpB,OAEpC,IAAK,IAAID,EAAI,EAAGA,GAAKT,MAAQtB,GAASgC,OAAQD,KAC3CT,MAAQtB,GAASoD,SAASA,EAASrB,IAAM,UAG3CT,MAAQtB,GAASgC,OAAS;;;;;;;KAY/B3B,KAAK8C,IAAIE,SAAW,CAClBC,UAAW,SAAUC,GACnB,OAAOA,GAETC,MAAO,WACL,OAAOlC,MAAQtB,GAEjByD,SAAU,WACR,OAAO;;;;;;;KAWXpD,KAAK8C,IAAIO,MAAQ,CACfJ,UAAW,WACT,OAAOhC,MAAQtB,GAEjBwD,MAAO,SAAUD,GACf,OAAOA,GAETE,SAAU,WACR,OAAO;;;;;;KAUXpD,KAAK8C,IAAID,UAAUO,SAAW,SAAUE,GACtC,SAAUrC,MAAQtB,GAASoD,SAASO;;;;;;;KAWtCtD,KAAK8C,IAAID,UAAUI,UAAY,SAAUC,GACvC,IAAIK,EACAC,EACAT,EACAU,EAAe,GAEnB,GAAIP,IAAUlD,KAAK8C,IAAIE,SACrB,OAAO/B,MAAQtB,EAGjB,GAAIuD,IAAUlD,KAAK8C,IAAIO,MACrB,OAAOH,EAGT,IAAKjC,MAAQtB,GAASgC,OAASuB,EAAMvB,OAAQ,CAC3C4B,EAAItC,MAAQtB,EACZ6D,EAAIN,MACC,CACLK,EAAIL,EACJM,EAAIvC,MAAQtB,EAGdoD,EAAWxB,OAAOE,KAAK8B,EAAER,UAEzB,IAAK,IAAIrB,EAAI,EAAGA,EAAIqB,EAASpB,OAAQD,IAAK,CACxC,IAAIgC,EAAUX,EAASrB,GAEnBgC,KAAWF,EAAET,UACfU,EAAaE,KAAKD,GAItB,OAAO,IAAI1D,KAAK8C,IAAIW;;;;;;KAUtBzD,KAAK8C,IAAID,UAAUM,MAAQ,SAAUD,GACnC,OAAIA,IAAUlD,KAAK8C,IAAIE,SACdhD,KAAK8C,IAAIE,SAGdE,IAAUlD,KAAK8C,IAAIO,MACdpC,MAAQtB,EAGV,IAAIK,KAAK8C,IAAIvB,OAAOE,MAAMR,MAAQtB,GAASoD,UAAUa,OAAOrC,OAAOE,KAAKyB,EAAMH;;;;;;;;KAYvF/C,KAAK6D,IAAM,SAAUC,EAASC,GAC5B,IAAIC,EAAoB,EAExB,IAAK,IAAI5B,KAAa0B,EACH,UAAb1B,IAEJ4B,GAAqBzC,OAAOE,KAAKqC,EAAQ1B,IAAYT,QAGvD,IAAIsC,GAAKF,EAAgBC,EAAoB,KAAQA,EAAoB,IACzE,OAAOE,KAAKC,IAAI,EAAID,KAAKE,IAAIH;;;;;;;;KAY/BjE,KAAKqE,MAAQ,SAAUC,EAAKC,IACzBtD,MAAQtB,GAAS2E,IAAMA,GAAO,IAC9BrD,MAAQtB,GAAS4E,SAAWA,GAAY;;;;;KAS3CvE,KAAKqE,MAAMxB,UAAUzB,SAAW,WAC9B,OAAQH,MAAQtB,GAAS2E;;;;;;;;;;;;;;;;;;;KAwB3BtE,KAAKqE,MAAMxB,UAAU2B,OAAS,SAAUC,IACrCxD,MAAQtB,GAAS2E,IAAMG,GAAIxD,MAAQtB,GAAS2E,KAAMrD,MAAQtB,GAAS4E,UACpE,OAAOtD,MAAQtB;;;;;;;KAWjBK,KAAKqE,MAAMxB,UAAUxB,MAAQ,SAAUoD,GACrCA,EAAKA,GAAM,SAAUhC,GACnB,OAAOA,GAGT,OAAO,IAAIzC,KAAKqE,MAAMI,GAAIxD,MAAQtB,GAAS2E,KAAMrD,MAAQtB,GAAS4E,WAAYtD,MAAQtB,GAAS4E;;;;;;;;;;;;;;;;;;KA2BjGvE,KAAK0E,UAAY,SAAUvD,EAAKoD,GAC9B,GAAW,MAAPpD,QAAsBG,GAAPH,EACjB,MAAO,GAGT,GAAIW,MAAMC,QAAQZ,GAChB,OAAOA,EAAIwD,KAAI,SAAUC,GACvB,OAAO,IAAI5E,KAAKqE,MAAMrE,KAAKa,MAAMK,SAAS0D,GAAGC,cAAe7E,KAAKa,MAAMQ,MAAMkD,OAIjF,IAAID,EAAMnD,EAAIC,WAAWyD,cACrBC,EAAMR,EAAI3C,OACVoD,EAAS,GAEb,IAAK,IAAIC,EAAW,EAAGC,EAAa,EAAGD,GAAYF,EAAKE,IAAY,CAClE,IAAIE,EAAOZ,EAAIa,OAAOH,GAClBI,EAAcJ,EAAWC,EAE7B,GAAIC,EAAKG,MAAMrF,KAAK0E,UAAUY,YAAcN,GAAYF,EAAK,CAC3D,GAAIM,EAAc,EAAG,CACnB,IAAIG,EAAgBvF,KAAKa,MAAMQ,MAAMkD,IAAa,GAClDgB,EAAc,YAAc,CAACN,EAAYG,GACzCG,EAAc,SAAWR,EAAOpD,OAChCoD,EAAOpB,KAAK,IAAI3D,KAAKqE,MAAMC,EAAItC,MAAMiD,EAAYD,GAAWO,IAG9DN,EAAaD,EAAW,GAI5B,OAAOD,GAWT/E,KAAK0E,UAAUY,UAAY,UAoC3BtF,KAAKwF,SAAW,YACbvE,MAAQtB,GAAS8F,OAAS,IAG7BzF,KAAKwF,SAASE,oBAAsBnE,OAAOC,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;KAmClDxB,KAAKwF,SAASG,iBAAmB,SAAUlB,EAAImB,GACzCA,KAAU3E,MAAQtB,GAAS+F,qBAC7B1F,KAAKa,MAAMC,KAAK,6CAA+C8E,GAGjEnB,EAAGmB,MAAQA,EACX5F,KAAKwF,SAASE,oBAAoBjB,EAAGmB,OAASnB;;;;;;KAUhDzE,KAAKwF,SAASK,4BAA8B,SAAUpB,GACpD,IAAIqB,EAAerB,EAAGmB,OAASnB,EAAGmB,SAAU3E,MAAQtB,GAAS+F,oBAExDI,GACH9F,KAAKa,MAAMC,KAAK,kGAAmG2D;;;;;;;;;;KAevHzE,KAAKwF,SAASO,KAAO,SAAUC,GAC7B,IAAI5F,EAAW,IAAIJ,KAAKwF,SACxBQ,EAAWC,SAAQ,SAAUC,GAC3B,IAAIzB,EAAKzE,KAAKwF,SAASE,oBAAoBQ,GAE3C,IAAIzB,EAGF,MAAM,IAAI0B,MAAM,sCAAwCD,GAFxD9F,EAASC,IAAIoE,MAKjB,OAAOrE;;;;;;;KAWTJ,KAAKwF,SAAS3C,UAAUxC,IAAM,WAC5B,IAAI+F,EAAMtE,MAAMe,UAAUb,MAAMtB,KAAK2F,WACrCD,EAAIH,SAAQ,SAAUxB,GACpBzE,KAAKwF,SAASK,4BAA4BpB,IAEzCxD,MAAQtB,GAAS8F,OAAO9B,KAAKc,KAC7BxD,MAAQtB;;;;;;;;;KAabK,KAAKwF,SAAS3C,UAAUyD,MAAQ,SAAUC,EAAYC,GACpDxG,KAAKwF,SAASK,4BAA4BW,GAE1C,IAAIC,GAAOxF,MAAQtB,GAAS8F,OAAO9C,QAAQ4D,GAE3C,IAAY,GAARE,EACF,MAAM,IAAIN,MAAM,0BAGlBM,GAAY,GAEXxF,MAAQtB,GAAS8F,OAAOiB,OAAOD,EAAK,EAAGD;;;;;;;;;KAa1CxG,KAAKwF,SAAS3C,UAAU8D,OAAS,SAAUJ,EAAYC,GACrDxG,KAAKwF,SAASK,4BAA4BW,GAE1C,IAAIC,GAAOxF,MAAQtB,GAAS8F,OAAO9C,QAAQ4D,GAE3C,IAAY,GAARE,EACF,MAAM,IAAIN,MAAM,2BAGjBlF,MAAQtB,GAAS8F,OAAOiB,OAAOD,EAAK,EAAGD;;;;;KAS1CxG,KAAKwF,SAAS3C,UAAU+D,OAAS,SAAUnC,GACzC,IAAIgC,GAAOxF,MAAQtB,GAAS8F,OAAO9C,QAAQ8B,IAE/B,GAARgC,IAIHxF,MAAQtB,GAAS8F,OAAOiB,OAAOD,EAAK;;;;;;;KAWvCzG,KAAKwF,SAAS3C,UAAUgE,IAAM,SAAU9B,GACtC,IAAI+B,GAAe7F,MAAQtB,GAAS8F,OAAO9D,OAE3C,IAAK,IAAID,EAAI,EAAGA,EAAIoF,EAAapF,IAAK,CACpC,IAAI+C,GAAMxD,MAAQtB,GAAS8F,OAAO/D,GAClC,IAAIqF,EAAO,GAEX,IAAK,IAAIC,EAAI,EAAGA,EAAIjC,EAAOpD,OAAQqF,IAAK,CACtC,IAAIC,EAASxC,EAAGM,EAAOiC,GAAIA,EAAGjC,GAC9B,GAAe,OAAXkC,QAAmC,IAAhBA,GAAgC,KAAXA,EAE5C,GAAInF,MAAMC,QAAQkF,GAChB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAOtF,OAAQuF,IACjCH,EAAKpD,KAAKsD,EAAOC,SAGnBH,EAAKpD,KAAKsD,GAIdlC,EAASgC,EAGX,OAAOhC;;;;;;;;;;KAcT/E,KAAKwF,SAAS3C,UAAUsE,UAAY,SAAU7C,EAAKC,GACjD,IAAI6C,EAAQ,IAAIpH,KAAKqE,MAAMC,EAAKC,GAChC,OAAOtD,KAAK4F,IAAI,CAACO,IAAQzC,KAAI,SAAUC,GACrC,OAAOA,EAAExD,eASbpB,KAAKwF,SAAS3C,UAAUwE,MAAQ,YAC7BpG,MAAQtB,GAAS8F,OAAS;;;;;;;KAW7BzF,KAAKwF,SAAS3C,UAAUyE,OAAS,WAC/B,OAAQrG,MAAQtB,GAAS8F,OAAOd,KAAI,SAAUF,GAC5CzE,KAAKwF,SAASK,4BAA4BpB,GAC1C,OAAOA,EAAGmB;;;;;;;;;;;;;;;;KA0Bd5F,KAAKuH,OAAS,SAAUxE,IACrB9B,MAAQtB,GAAS6H,WAAa,GAC9BvG,MAAQtB,GAASoD,SAAWA,GAAY;;;;;;;;;;KAc3C/C,KAAKuH,OAAO1E,UAAU4E,iBAAmB,SAAUC,GAEjD,GAAyC,IAApCzG,MAAQtB,GAASoD,SAASpB,OAC7B,OAAO,EAGT,IAAIgG,EAAQ,EACRC,GAAO3G,MAAQtB,GAASoD,SAASpB,OAAS,EAC1CyD,EAAcwC,EAAMD,EACpBE,EAAa3D,KAAK4D,MAAM1C,EAAc,GACtC2C,GAAc9G,MAAQtB,GAASoD,SAAsB,EAAb8E,GAE5C,MAAOzC,EAAc,EAAG,CAClB2C,EAAaL,IACfC,EAAQE,GAGNE,EAAaL,IACfE,EAAMC,GAGR,GAAIE,GAAcL,EAChB,MAGFtC,EAAcwC,EAAMD,EACpBE,EAAaF,EAAQzD,KAAK4D,MAAM1C,EAAc,GAC9C2C,GAAc9G,MAAQtB,GAASoD,SAAsB,EAAb8E,GAG1C,OAAIE,GAAcL,GAIdK,EAAaL,EAHK,EAAbG,EAOLE,EAAaL,EACW,GAAlBG,EAAa,QADvB;;;;;;;;;KAeF7H,KAAKuH,OAAO1E,UAAUmF,OAAS,SAAUC,EAAWpG,GAClDZ,KAAKiH,OAAOD,EAAWpG,GAAK,WAC1B,KAAM;;;;;;;;KAaV7B,KAAKuH,OAAO1E,UAAUqF,OAAS,SAAUD,EAAWpG,EAAK4C,IACtDxD,MAAQtB,GAAS6H,WAAa,EAC/B,IAAIW,EAAWlH,KAAKwG,iBAAiBQ,IAEhChH,MAAQtB,GAASoD,SAASoF,IAAaF,GACzChH,MAAQtB,GAASoD,SAASoF,EAAW,GAAK1D,GAAIxD,MAAQtB,GAASoD,SAASoF,EAAW,GAAItG,IAEvFZ,MAAQtB,GAASoD,SAAS2D,OAAOyB,EAAU,EAAGF,EAAWpG;;;;;KAU9D7B,KAAKuH,OAAO1E,UAAUuF,UAAY,WAChC,IAAKnH,MAAQtB,GAAS6H,WAAY,OAAQvG,MAAQtB,GAAS6H,WAC3D,IAAIa,EAAe,EACfC,GAAkBrH,MAAQtB,GAASoD,SAASpB,OAEhD,IAAK,IAAID,EAAI,EAAGA,EAAI4G,EAAgB5G,GAAK,EAAG,CAC1C,IAAIG,GAAOZ,MAAQtB,GAASoD,SAASrB,GACrC2G,GAAgBxG,EAAMA,EAGxB,OAAQZ,MAAQtB,GAAS6H,WAAatD,KAAKqE,KAAKF;;;;;;KAUlDrI,KAAKuH,OAAO1E,UAAU2F,IAAM,SAAUC,GACpC,IAAIC,EAAa,EACbnF,GAAKtC,MAAQtB,GAASoD,SACtBS,EAAIiF,EAAY1F,SAChB4F,EAAOpF,EAAE5B,OACTiH,EAAOpF,EAAE7B,OACTkH,EAAO,EACPC,EAAO,EACPpH,EAAI,EACJsF,EAAI,EAER,MAAOtF,EAAIiH,GAAQ3B,EAAI4B,EAAM,CAC3BC,EAAOtF,EAAE7B,GAAIoH,EAAOtF,EAAEwD,GAEtB,GAAI6B,EAAOC,EACTpH,GAAK,OACA,GAAImH,EAAOC,EAChB9B,GAAK,OACA,GAAI6B,GAAQC,EAAM,CACvBJ,GAAcnF,EAAE7B,EAAI,GAAK8B,EAAEwD,EAAI,GAC/BtF,GAAK,EACLsF,GAAK,GAIT,OAAO0B;;;;;;;KAWT1I,KAAKuH,OAAO1E,UAAUkG,WAAa,SAAUN,GAC3C,OAAOxH,KAAKuH,IAAIC,GAAexH,KAAKmH,aAAe;;;;;KASrDpI,KAAKuH,OAAO1E,UAAUmG,QAAU,WAC9B,IAAIC,EAAS,IAAInH,OAAOb,MAAQtB,GAASoD,SAASpB,OAAS,GAE3D,IAAK,IAAID,EAAI,EAAGsF,EAAI,EAAGtF,GAAKT,MAAQtB,GAASoD,SAASpB,OAAQD,GAAK,EAAGsF,IACpEiC,EAAOjC,IAAM/F,MAAQtB,GAASoD,SAASrB,GAGzC,OAAOuH;;;;;KASTjJ,KAAKuH,OAAO1E,UAAUyE,OAAS,WAC7B,OAAQrG,MAAQtB,GAASoD;;;;;;;;;;;KAuB3B/C,KAAKQ,QAAU,WACb,IAAI0I,EAAY,CACdC,QAAW,MACXC,OAAU,OACVC,KAAQ,OACRC,KAAQ,OACRC,KAAQ,MACRC,IAAO,MACPC,KAAQ,KACRC,MAAS,MACTC,IAAO,IACPC,MAAS,MACTC,QAAW,MACXC,MAAS,MACTC,KAAQ,MACRC,MAAS,KACTC,QAAW,MACXC,QAAW,MACXC,QAAW,MACXC,MAAS,KACTC,MAAS,MACTC,OAAU,MACVC,KAAQ,OAENC,EAAY,CACdC,MAAS,KACTC,MAAS,GACTC,MAAS,KACTC,MAAS,KACTC,KAAQ,KACRC,IAAO,GACPC,KAAQ,IAENC,EAAI,WAERC,EAAI,WAEJC,EAAIF,EAAI,aAERG,EAAIF,EAAI,WAERG,EAAO,KAAOF,EAAI,KAAOC,EAAID,EAE7BG,EAAO,KAAOH,EAAI,KAAOC,EAAID,EAAI,IAAMC,EAAI,MAE3CG,EAAO,KAAOJ,EAAI,KAAOC,EAAID,EAAIC,EAAID,EAErCK,EAAM,KAAOL,EAAI,KAAOD,EAExB,IAAIO,EAAU,IAAIC,OAAOL,GACzB,IAAIM,EAAU,IAAID,OAAOH,GACzB,IAAIK,EAAU,IAAIF,OAAOJ,GACzB,IAAIO,EAAS,IAAIH,OAAOF,GACxB,IAAIM,EAAQ,kBACZ,IAAIC,EAAS,iBACb,IAAIC,EAAQ,aACZ,IAAIC,EAAS,kBACb,IAAIC,EAAU,KACd,IAAIC,EAAW,cACf,IAAIC,EAAW,IAAIV,OAAO,sBAC1B,IAAIW,EAAW,IAAIX,OAAO,IAAMP,EAAID,EAAI,gBACxC,IAAIoB,EAAQ,mBACZ,IAAIC,EAAO,2IACX,IAAIC,EAAO,iDACX,IAAIC,EAAO,sFACX,IAAIC,EAAQ,oBACZ,IAAIC,EAAO,WACX,IAAIC,EAAS,MACb,IAAIC,EAAQ,IAAInB,OAAO,IAAMP,EAAID,EAAI,gBAErC,IAAI4B,EAAgB,SAASA,cAAcC,GACzC,IAAIC,EAAMC,EAAQC,EAASC,EAAIC,EAAKC,EAAKC,EAEzC,GAAIP,EAAEnL,OAAS,EACb,OAAOmL,EAGTG,EAAUH,EAAEQ,OAAO,EAAG,GAEP,KAAXL,IACFH,EAAIG,EAAQM,cAAgBT,EAAEQ,OAAO,IAIvCJ,EAAKrB,EACLsB,EAAMrB,EAEFoB,EAAGM,KAAKV,GACVA,EAAIA,EAAEW,QAAQP,EAAI,QACTC,EAAIK,KAAKV,KAClBA,EAAIA,EAAEW,QAAQN,EAAK,SAIrBD,EAAKnB,EACLoB,EAAMnB,EAEN,GAAIkB,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBI,EAAK1B,EAEL,GAAI0B,EAAGM,KAAKE,EAAG,IAAK,CAClBR,EAAKjB,EACLa,EAAIA,EAAEW,QAAQP,EAAI,UAEf,GAAIC,EAAIK,KAAKV,GAAI,CACtB,IAAIY,EAAKP,EAAIQ,KAAKb,GAClBC,EAAOW,EAAG,GACVP,EAAMvB,EAEN,GAAIuB,EAAIK,KAAKT,GAAO,CAClBD,EAAIC,EACJI,EAAMjB,EACNkB,EAAMjB,EACNkB,EAAMjB,EAEN,GAAIe,EAAIK,KAAKV,GACXA,GAAQ,SACH,GAAIM,EAAII,KAAKV,GAAI,CACtBI,EAAKjB,EACLa,EAAIA,EAAEW,QAAQP,EAAI,SACTG,EAAIG,KAAKV,KAClBA,GAAQ,MAMdI,EAAKb,EAEL,GAAIa,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBC,EAAOW,EAAG,GACVZ,EAAIC,EAAO,IAIbG,EAAKZ,EAEL,GAAIY,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBC,EAAOW,EAAG,GACVV,EAASU,EAAG,GACZR,EAAK1B,EAED0B,EAAGM,KAAKT,KACVD,EAAIC,EAAO7D,EAAU8D,IAKzBE,EAAKX,EAEL,GAAIW,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBC,EAAOW,EAAG,GACVV,EAASU,EAAG,GACZR,EAAK1B,EAED0B,EAAGM,KAAKT,KACVD,EAAIC,EAAOvC,EAAUwC,IAKzBE,EAAKV,EACLW,EAAMV,EAEN,GAAIS,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBC,EAAOW,EAAG,GACVR,EAAKxB,EAEDwB,EAAGM,KAAKT,KACVD,EAAIC,QAED,GAAII,EAAIK,KAAKV,GAAI,CACtB,IAAIY,EAAKP,EAAIQ,KAAKb,GAClBC,EAAOW,EAAG,GAAKA,EAAG,GAClBP,EAAMzB,EAEFyB,EAAIK,KAAKT,KACXD,EAAIC,GAKRG,EAAKR,EAEL,GAAIQ,EAAGM,KAAKV,GAAI,CACd,IAAIY,EAAKR,EAAGS,KAAKb,GACjBC,EAAOW,EAAG,GACVR,EAAKxB,EACLyB,EAAMxB,EACNyB,EAAMR,GAEFM,EAAGM,KAAKT,IAASI,EAAIK,KAAKT,KAAUK,EAAII,KAAKT,MAC/CD,EAAIC,GAIRG,EAAKP,EACLQ,EAAMzB,EAEN,GAAIwB,EAAGM,KAAKV,IAAMK,EAAIK,KAAKV,GAAI,CAC7BI,EAAKjB,EACLa,EAAIA,EAAEW,QAAQP,EAAI,IAIL,KAAXD,IACFH,EAAIG,EAAQpI,cAAgBiI,EAAEQ,OAAO,IAGvC,OAAOR,GAGT,OAAO,SAAU1F,GACf,OAAOA,EAAM5C,OAAOqI,IA1NT,GA8Nf7M,KAAKwF,SAASG,iBAAiB3F,KAAKQ,QAAS;;;;;;;;;;;;;KAoB7CR,KAAK4N,uBAAyB,SAAUC,GACtC,IAAIC,EAAQD,EAAUE,QAAO,SAAUhH,EAAMiH,GAC3CjH,EAAKiH,GAAYA,EACjB,OAAOjH,IACN,IACH,OAAO,SAAUK,GACf,GAAIA,GAAS0G,EAAM1G,EAAMhG,cAAgBgG,EAAMhG,WAAY,OAAOgG;;;;;;;;;;;;;KAkBtEpH,KAAKO,eAAiBP,KAAK4N,uBAAuB,CAAC,IAAK,OAAQ,QAAS,SAAU,QAAS,MAAO,SAAU,OAAQ,KAAM,QAAS,KAAM,MAAO,MAAO,MAAO,KAAM,KAAM,KAAM,UAAW,OAAQ,MAAO,KAAM,MAAO,SAAU,QAAS,OAAQ,MAAO,KAAM,OAAQ,SAAU,OAAQ,OAAQ,QAAS,MAAO,OAAQ,MAAO,MAAO,MAAO,MAAO,OAAQ,KAAM,MAAO,OAAQ,MAAO,MAAO,MAAO,UAAW,IAAK,KAAM,KAAM,OAAQ,KAAM,KAAM,MAAO,OAAQ,QAAS,MAAO,OAAQ,SAAU,MAAO,KAAM,QAAS,OAAQ,OAAQ,KAAM,UAAW,KAAM,MAAO,MAAO,KAAM,MAAO,QAAS,KAAM,OAAQ,KAAM,QAAS,MAAO,MAAO,SAAU,OAAQ,MAAO,OAAQ,MAAO,SAAU,QAAS,KAAM,OAAQ,OAAQ,OAAQ,MAAO,QAAS,OAAQ,OAAQ,QAAS,QAAS,OAAQ,OAAQ,MAAO,KAAM,MAAO,OAAQ,KAAM,QAAS,MAAO,KAAM,OAAQ,OAAQ,OAAQ,QAAS,QAAS,QAAS,MAAO,OAAQ,MAAO,OAAQ,OAAQ,QAAS,MAAO,MAAO,SACx7B5N,KAAKwF,SAASG,iBAAiB3F,KAAKO,eAAgB;;;;;;;;;;;;;;;KAsBpDP,KAAKM,QAAU,SAAU8G,GACvB,OAAOA,EAAM5C,QAAO,SAAU/B,GAC5B,OAAOA,EAAEgL,QAAQ,OAAQ,IAAIA,QAAQ,OAAQ,QAIjDzN,KAAKwF,SAASG,iBAAiB3F,KAAKM,QAAS,WA4B7CN,KAAKiO,SAAW,YACbhN,MAAQtB,GAASuO,MAAQ,OACzBjN,MAAQtB,GAASwO,MAAQ,IACzBlN,MAAQtB,GAASyO,GAAKpO,KAAKiO,SAASI,QACrCrO,KAAKiO,SAASI,SAAW,GAY3BrO,KAAKiO,SAASI,QAAU;;;;;;;KASxBrO,KAAKiO,SAASK,UAAY,SAAUC,GAClC,IAAIrO,EAAU,IAAIF,KAAKiO,SAAS9N,QAEhC,IAAK,IAAIuB,EAAI,EAAGoD,EAAMyJ,EAAI5M,OAAQD,EAAIoD,EAAKpD,IACzCxB,EAAQ8H,OAAOuG,EAAI7M,IAGrBxB,EAAQsO,SACR,OAAOtO,EAAQuO;;;;;;;;;KAajBzO,KAAKiO,SAASS,WAAa,SAAUC,GACnC,MAAI,iBAAkBA,EACb3O,KAAKiO,SAASW,gBAAgBD,EAAOE,KAAMF,EAAOG,cAElD9O,KAAKiO,SAASzL,WAAWmM,EAAOE;;;;;;;;;;;;;;;KAoB3C7O,KAAKiO,SAASW,gBAAkB,SAAUtK,EAAKwK,GAC7C,IAAIL,EAAO,IAAIzO,KAAKiO,SACpB,IAAIc,EAAQ,CAAC,CACXC,KAAMP,EACNQ,eAAgBH,EAChBxK,IAAKA,IAGP,MAAOyK,EAAMpN,OAAQ,CACnB,IAAIuN,EAAQH,EAAMI,MAElB,GAAID,EAAM5K,IAAI3C,OAAS,EAAG,CACxB,IAAIuD,EAAOgK,EAAM5K,IAAIa,OAAO,GACxBiK,EAEJ,GAAIlK,KAAQgK,EAAMF,KAAKb,MACrBiB,EAAaF,EAAMF,KAAKb,MAAMjJ,OACzB,CACLkK,EAAa,IAAIpP,KAAKiO,SACtBiB,EAAMF,KAAKb,MAAMjJ,GAAQkK,EAGH,GAApBF,EAAM5K,IAAI3C,SACZyN,EAAWlB,MAAQ,MAGrBa,EAAMpL,KAAK,CACTqL,KAAMI,EACNH,eAAgBC,EAAMD,eACtB3K,IAAK4K,EAAM5K,IAAItC,MAAM,KAIzB,GAA4B,GAAxBkN,EAAMD,eAAV,CAKA,GAAI,MAAOC,EAAMF,KAAKb,MACpB,IAAIkB,EAAgBH,EAAMF,KAAKb,MAAM,SAChC,CACL,IAAIkB,EAAgB,IAAIrP,KAAKiO,SAC7BiB,EAAMF,KAAKb,MAAM,KAAOkB,EAGF,GAApBH,EAAM5K,IAAI3C,SACZ0N,EAAcnB,MAAQ,MAGxBa,EAAMpL,KAAK,CACTqL,KAAMK,EACNJ,eAAgBC,EAAMD,eAAiB,EACvC3K,IAAK4K,EAAM5K,MAKT4K,EAAM5K,IAAI3C,OAAS,GACrBoN,EAAMpL,KAAK,CACTqL,KAAME,EAAMF,KACZC,eAAgBC,EAAMD,eAAiB,EACvC3K,IAAK4K,EAAM5K,IAAItC,MAAM,KAMD,GAApBkN,EAAM5K,IAAI3C,SACZuN,EAAMF,KAAKd,MAAQ,MAMrB,GAAIgB,EAAM5K,IAAI3C,QAAU,EAAG,CACzB,GAAI,MAAOuN,EAAMF,KAAKb,MACpB,IAAImB,EAAmBJ,EAAMF,KAAKb,MAAM,SACnC,CACL,IAAImB,EAAmB,IAAItP,KAAKiO,SAChCiB,EAAMF,KAAKb,MAAM,KAAOmB,EAGF,GAApBJ,EAAM5K,IAAI3C,SACZ2N,EAAiBpB,MAAQ,MAG3Ba,EAAMpL,KAAK,CACTqL,KAAMM,EACNL,eAAgBC,EAAMD,eAAiB,EACvC3K,IAAK4K,EAAM5K,IAAItC,MAAM,KAOzB,GAAIkN,EAAM5K,IAAI3C,OAAS,EAAG,CACxB,IAAI4N,EAAQL,EAAM5K,IAAIa,OAAO,GACzBqK,EAAQN,EAAM5K,IAAIa,OAAO,GACzBsK,EAEJ,GAAID,KAASN,EAAMF,KAAKb,MACtBsB,EAAgBP,EAAMF,KAAKb,MAAMqB,OAC5B,CACLC,EAAgB,IAAIzP,KAAKiO,SACzBiB,EAAMF,KAAKb,MAAMqB,GAASC,EAGJ,GAApBP,EAAM5K,IAAI3C,SACZ8N,EAAcvB,MAAQ,MAGxBa,EAAMpL,KAAK,CACTqL,KAAMS,EACNR,eAAgBC,EAAMD,eAAiB,EACvC3K,IAAKiL,EAAQL,EAAM5K,IAAItC,MAAM,OAKnC,OAAOyM;;;;;;;;;;KAcTzO,KAAKiO,SAASzL,WAAa,SAAU8B,GACnC,IAAI0K,EAAO,IAAIhP,KAAKiO,SAChBQ,EAAOO,EAUX,IAAK,IAAItN,EAAI,EAAGoD,EAAMR,EAAI3C,OAAQD,EAAIoD,EAAKpD,IAAK,CAC9C,IAAIwD,EAAOZ,EAAI5C,GACXwM,EAAQxM,GAAKoD,EAAM,EAEvB,GAAY,KAARI,EAAa,CACf8J,EAAKb,MAAMjJ,GAAQ8J,EACnBA,EAAKd,MAAQA,MACR,CACL,IAAIwB,EAAO,IAAI1P,KAAKiO,SACpByB,EAAKxB,MAAQA,EACbc,EAAKb,MAAMjJ,GAAQwK,EACnBV,EAAOU,GAIX,OAAOjB;;;;;;;;;;KAcTzO,KAAKiO,SAASpL,UAAUmG,QAAU,WAChC,IAAI8E,EAAQ,GACZ,IAAIiB,EAAQ,CAAC,CACXY,OAAQ,GACRX,KAAM/N,MAAQtB,IAGhB,MAAOoP,EAAMpN,OAAQ,CACnB,IAAIuN,EAAQH,EAAMI,MACdhB,EAAQ5M,OAAOE,KAAKyN,EAAMF,KAAKb,OAC/BrJ,EAAMqJ,EAAMxM,OAEhB,GAAIuN,EAAMF,KAAKd,MAAO,CAKpBgB,EAAMS,OAAOxK,OAAO,GACpB2I,EAAMnK,KAAKuL,EAAMS,QAGnB,IAAK,IAAIjO,EAAI,EAAGA,EAAIoD,EAAKpD,IAAK,CAC5B,IAAIkO,EAAOzB,EAAMzM,GACjBqN,EAAMpL,KAAK,CACTgM,OAAQT,EAAMS,OAAO/L,OAAOgM,GAC5BZ,KAAME,EAAMF,KAAKb,MAAMyB,MAK7B,OAAO9B;;;;;;;;;;KAcT9N,KAAKiO,SAASpL,UAAUzB,SAAW,WAQjC,IAAKH,MAAQtB,GAASkQ,KACpB,OAAQ5O,MAAQtB,GAASkQ,KAG3B,IAAIvL,GAAOrD,MAAQtB,GAASuO,MAAQ,IAAM,IACtC4B,EAASvO,OAAOE,MAAMR,MAAQtB,GAASwO,OAAO4B,OAC9CjL,EAAMgL,EAAOnO,OAEjB,IAAK,IAAID,EAAI,EAAGA,EAAIoD,EAAKpD,IAAK,CAC5B,IAAIkE,EAAQkK,EAAOpO,GACfsN,GAAQ/N,MAAQtB,GAASwO,MAAMvI,GACnCtB,EAAMA,EAAMsB,EAAQoJ,EAAKZ,GAG3B,OAAO9J;;;;;;;;;;KAcTtE,KAAKiO,SAASpL,UAAUI,UAAY,SAAUO,GAC5C,IAAIyF,EAAS,IAAIjJ,KAAKiO,SAClBiB,OAAQ5N,EACZ,IAAIyN,EAAQ,CAAC,CACXiB,MAAOxM,EACPyF,OAAQA,EACR+F,KAAM/N,MAAQtB,IAGhB,MAAOoP,EAAMpN,OAAQ,CACnBuN,EAAQH,EAAMI,MAKd,IAAIc,EAAS1O,OAAOE,KAAKyN,EAAMc,MAAM7B,OACjC+B,EAAOD,EAAOtO,OACdwO,EAAS5O,OAAOE,KAAKyN,EAAMF,KAAKb,OAChCiC,EAAOD,EAAOxO,OAElB,IAAK,IAAI0O,EAAI,EAAGA,EAAIH,EAAMG,IAAK,CAC7B,IAAIC,EAAQL,EAAOI,GAEnB,IAAK,IAAI3N,EAAI,EAAGA,EAAI0N,EAAM1N,IAAK,CAC7B,IAAI6N,EAAQJ,EAAOzN,GAEnB,GAAI6N,GAASD,GAAkB,KAATA,EAAc,CAClC,IAAItB,EAAOE,EAAMF,KAAKb,MAAMoC,GACxBP,EAAQd,EAAMc,MAAM7B,MAAMmC,GAC1BpC,EAAQc,EAAKd,OAAS8B,EAAM9B,MAC5BwB,OAAOpO,EAEX,GAAIiP,KAASrB,EAAMjG,OAAOkF,MAAO,CAI/BuB,EAAOR,EAAMjG,OAAOkF,MAAMoC,GAC1Bb,EAAKxB,MAAQwB,EAAKxB,OAASA,MACtB,CAILwB,EAAO,IAAI1P,KAAKiO,SAChByB,EAAKxB,MAAQA,EACbgB,EAAMjG,OAAOkF,MAAMoC,GAASb,EAG9BX,EAAMpL,KAAK,CACTqM,MAAOA,EACP/G,OAAQyG,EACRV,KAAMA,OAOhB,OAAO/F,GAGTjJ,KAAKiO,SAAS9N,QAAU,YACrBc,MAAQtB,GAAS6Q,aAAe,IAChCvP,MAAQtB,GAAS8O,KAAO,IAAIzO,KAAKiO,UACjChN,MAAQtB,GAAS8Q,eAAiB,IAClCxP,MAAQtB,GAAS+Q,eAAiB,IAGrC1Q,KAAKiO,SAAS9N,QAAQ0C,UAAUmF,OAAS,SAAU2I,GACjD,IAAI3B,EACA4B,EAAe,EAEnB,GAAID,GAAQ1P,MAAQtB,GAAS6Q,aAC3B,MAAM,IAAIrK,MAAM,+BAGlB,IAAK,IAAIzE,EAAI,EAAGA,EAAIiP,EAAKhP,QAAUD,GAAKT,MAAQtB,GAAS6Q,aAAa7O,OAAQD,IAAK,CACjF,GAAIiP,EAAKjP,KAAOT,MAAQtB,GAAS6Q,aAAa9O,GAAI,MAClDkP,IAGF3P,KAAK4P,SAASD,GAGZ5B,EAD6C,IAA1C/N,MAAQtB,GAAS8Q,eAAe9O,QAC3BV,MAAQtB,GAAS8O,MAEjBxN,MAAQtB,GAAS8Q,gBAAgBxP,MAAQtB,GAAS8Q,eAAe9O,OAAS,GAAGmP,MAGvF,IAAK,IAAIpP,EAAIkP,EAAclP,EAAIiP,EAAKhP,OAAQD,IAAK,CAC/C,IAAIqP,EAAW,IAAI/Q,KAAKiO,SACpB/I,EAAOyL,EAAKjP,GAChBsN,EAAKb,MAAMjJ,GAAQ6L,GAElB9P,MAAQtB,GAAS8Q,eAAe9M,KAAK,CACpCqN,OAAQhC,EACR9J,KAAMA,EACN4L,MAAOC,IAGT/B,EAAO+B,EAGT/B,EAAKd,MAAQ,MACZjN,MAAQtB,GAAS6Q,aAAeG,GAGnC3Q,KAAKiO,SAAS9N,QAAQ0C,UAAU2L,OAAS,WACvCvN,KAAK4P,SAAS,IAGhB7Q,KAAKiO,SAAS9N,QAAQ0C,UAAUgO,SAAW,SAAUI,GACnD,IAAK,IAAIvP,GAAKT,MAAQtB,GAAS8Q,eAAe9O,OAAS,EAAGD,GAAKuP,EAAQvP,IAAK,CAC1E,IAAIsN,GAAQ/N,MAAQtB,GAAS8Q,eAAe/O,GACxCwP,EAAWlC,EAAK8B,MAAM1P,WAE1B,GAAI8P,KAAajQ,MAAQtB,GAAS+Q,eAChC1B,EAAKgC,OAAO7C,MAAMa,EAAK9J,OAASjE,MAAQtB,GAAS+Q,eAAeQ,OAC3D,CAGLlC,EAAK8B,MAAMjB,KAAOqB,GACjBjQ,MAAQtB,GAAS+Q,eAAeQ,GAAYlC,EAAK8B,OAGnD7P,MAAQtB,GAAS8Q,eAAetB;;;;;;;;;;;;;;;;KA0BrCnP,KAAKmR,MAAQ,SAAUC,IACpBnQ,MAAQtB,GAAS0R,cAAgBD,EAAMC,eACvCpQ,MAAQtB,GAAS2R,aAAeF,EAAME,cACtCrQ,MAAQtB,GAAS4R,SAAWH,EAAMG,UAClCtQ,MAAQtB,GAAS6R,OAASJ,EAAMI,QAChCvQ,MAAQtB,GAASS,SAAWgR,EAAMhR;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;KA2ErCJ,KAAKmR,MAAMtO,UAAU4O,OAAS,SAAUC,GACtC,OAAOzQ,KAAK0Q,OAAM,SAAUA,GAC1B,IAAIC,EAAS,IAAI5R,KAAK6R,YAAYH,EAAaC,GAC/CC,EAAOE;;;;;;;;;;;;;;;;;;;;;;;;KA8BX9R,KAAKmR,MAAMtO,UAAU8O,MAAQ,SAAUlN,GAOrC,IAAIkN,EAAQ,IAAI3R,KAAK+R,OAAO9Q,MAAQtB,GAAS6R,QACzCQ,EAAiBzQ,OAAOC,OAAO,MAC/ByQ,EAAe1Q,OAAOC,OAAO,MAC7B0Q,EAAiB3Q,OAAOC,OAAO,MAC/B2Q,EAAkB5Q,OAAOC,OAAO,MAChC4Q,EAAoB7Q,OAAOC,OAAO,MAOtC,IAAK,IAAIE,EAAI,EAAGA,GAAKT,MAAQtB,GAAS6R,OAAO7P,OAAQD,IACnDuQ,GAAchR,MAAQtB,GAAS6R,OAAO9P,IAAM,IAAI1B,KAAKuH,OAGvD9C,EAAG/D,KAAKiR,EAAOA,GAEf,IAAK,IAAIjQ,EAAI,EAAGA,EAAIiQ,EAAMU,QAAQ1Q,OAAQD,IAAK,CAS7C,IAAIiN,EAASgD,EAAMU,QAAQ3Q,GACvB4Q,EAAQ,KACRC,EAAgBvS,KAAK8C,IAAIO,MAG3BiP,EADE3D,EAAO6D,aACAvR,MAAQtB,GAASS,SAAS+G,UAAUwH,EAAOE,KAAM,CACxD2C,OAAQ7C,EAAO6C,SAGT,CAAC7C,EAAOE,MAGlB,IAAK,IAAI4D,EAAI,EAAGA,EAAIH,EAAM3Q,OAAQ8Q,IAAK,CACrC,IAAI5D,EAAOyD,EAAMG,GAQjB9D,EAAOE,KAAOA,EAOd,IAAI6D,EAAe1S,KAAKiO,SAASS,WAAWC,GACxCgE,GAAiB1R,MAAQtB,GAAS4R,SAAStO,UAAUyP,GAAc1J,UASvE,GAA6B,IAAzB2J,EAAchR,QAAgBgN,EAAOiE,WAAa5S,KAAK+R,MAAMa,SAASC,SAAU,CAClF,IAAK,IAAI3L,EAAI,EAAGA,EAAIyH,EAAO6C,OAAO7P,OAAQuF,IAAK,CAC7C,IAAI4L,EAAQnE,EAAO6C,OAAOtK,GAC1BiL,EAAgBW,GAAS9S,KAAK8C,IAAIO,MAGpC,MAGF,IAAK,IAAI2D,EAAI,EAAGA,EAAI2L,EAAchR,OAAQqF,IAAK,CAK7C,IAAI+L,EAAeJ,EAAc3L,GAC7BlD,GAAW7C,MAAQtB,GAAS0R,cAAc0B,GAC1CC,EAAYlP,EAAQmP,OAExB,IAAK,IAAI/L,EAAI,EAAGA,EAAIyH,EAAO6C,OAAO7P,OAAQuF,IAAK,CAS7C,IAAI4L,EAAQnE,EAAO6C,OAAOtK,GACtBgM,EAAepP,EAAQgP,GACvBK,EAAuB5R,OAAOE,KAAKyR,GACnCE,EAAYL,EAAe,IAAMD,EACjCO,EAAuB,IAAIrT,KAAK8C,IAAIqQ,GAOxC,GAAIxE,EAAOiE,UAAY5S,KAAK+R,MAAMa,SAASC,SAAU,CACnDN,EAAgBA,EAAcpP,MAAMkQ,QAEL/R,IAA3B6Q,EAAgBW,KAClBX,EAAgBW,GAAS9S,KAAK8C,IAAIE,UAUtC,GAAI2L,EAAOiE,UAAY5S,KAAK+R,MAAMa,SAASU,WAA3C,CAuBArB,EAAaa,GAAO5K,OAAO8K,EAAWrE,EAAO4E,OAAO,SAAUhQ,EAAGC,GAC/D,OAAOD,EAAIC,KAOb,IAAI0O,EAAekB,GAAnB,CAIA,IAAK,IAAII,EAAI,EAAGA,EAAIL,EAAqBxR,OAAQ6R,IAAK,CAOpD,IAAIC,EAAsBN,EAAqBK,GAC3CE,EAAmB,IAAI1T,KAAKkC,SAASuR,EAAqBX,GAC1DvO,EAAW2O,EAAaO,GACxBE,OAEoDrS,KAAnDqS,EAAa3B,EAAe0B,IAC/B1B,EAAe0B,GAAoB,IAAI1T,KAAK4T,UAAUb,EAAcD,EAAOvO,GAE3EoP,EAAWtT,IAAI0S,EAAcD,EAAOvO,GAIxC2N,EAAekB,GAAa,UAtD5B,MACmC9R,IAA7B8Q,EAAkBU,KACpBV,EAAkBU,GAAS9S,KAAK8C,IAAIO,OAGtC+O,EAAkBU,GAASV,EAAkBU,GAAO3P,MAAMkQ,MA6DlE,GAAI1E,EAAOiE,WAAa5S,KAAK+R,MAAMa,SAASC,SAC1C,IAAK,IAAI3L,EAAI,EAAGA,EAAIyH,EAAO6C,OAAO7P,OAAQuF,IAAK,CAC7C,IAAI4L,EAAQnE,EAAO6C,OAAOtK,GAC1BiL,EAAgBW,GAASX,EAAgBW,GAAO7P,UAAUsP,IAWhE,IAAIsB,EAAqB7T,KAAK8C,IAAIE,SAC9B8Q,EAAuB9T,KAAK8C,IAAIO,MAEpC,IAAK,IAAI3B,EAAI,EAAGA,GAAKT,MAAQtB,GAAS6R,OAAO7P,OAAQD,IAAK,CACxD,IAAIoR,GAAS7R,MAAQtB,GAAS6R,OAAO9P,GAEjCyQ,EAAgBW,KAClBe,EAAqBA,EAAmB5Q,UAAUkP,EAAgBW,KAGhEV,EAAkBU,KACpBgB,EAAuBA,EAAqB3Q,MAAMiP,EAAkBU,KAIxE,IAAIiB,EAAoBxS,OAAOE,KAAKuQ,GAChCgC,EAAU,GACVC,EAAU1S,OAAOC,OAAO,MAY5B,GAAImQ,EAAMuC,YAAa,CACrBH,EAAoBxS,OAAOE,MAAMR,MAAQtB,GAAS2R,cAElD,IAAK,IAAI5P,EAAI,EAAGA,EAAIqS,EAAkBpS,OAAQD,IAAK,CACjD,IAAIgS,EAAmBK,EAAkBrS,GACzC,IAAIkB,EAAW5C,KAAKkC,SAASM,WAAWkR,GACxC1B,EAAe0B,GAAoB,IAAI1T,KAAK4T,WAIhD,IAAK,IAAIlS,EAAI,EAAGA,EAAIqS,EAAkBpS,OAAQD,IAAK,CASjD,IAAIkB,EAAW5C,KAAKkC,SAASM,WAAWuR,EAAkBrS,IACtDS,EAASS,EAAST,OAEtB,GAAK0R,EAAmBzQ,SAASjB,KAI7B2R,EAAqB1Q,SAASjB,GAAlC,CAIA,IAAIgS,GAAelT,MAAQtB,GAAS2R,aAAa1O,GAC7CwR,EAAQnC,EAAarP,EAASR,WAAW2G,WAAWoL,GACpDE,EAEJ,QAAqC/S,KAAhC+S,EAAWJ,EAAQ9R,IAAwB,CAC9CkS,EAASD,OAASA,EAClBC,EAASC,UAAUC,QAAQvC,EAAepP,QACrC,CACL,IAAIyC,EAAQ,CACVmP,IAAKrS,EACLiS,MAAOA,EACPE,UAAWtC,EAAepP,IAE5BqR,EAAQ9R,GAAUkD,EAClB2O,EAAQrQ,KAAK0B,KAQjB,OAAO2O,EAAQjE,MAAK,SAAUxM,EAAGC,GAC/B,OAAOA,EAAE4Q,MAAQ7Q,EAAE6Q;;;;;;;;KAavBpU,KAAKmR,MAAMtO,UAAUyE,OAAS,WAC5B,IAAI+J,EAAgB9P,OAAOE,MAAMR,MAAQtB,GAAS0R,eAAetB,OAAOpL,KAAI,SAAUkK,GACpF,MAAO,CAACA,GAAO5N,MAAQtB,GAAS0R,cAAcxC,MAC7C5N,MAAQtB,GACX,IAAI2R,EAAe/P,OAAOE,MAAMR,MAAQtB,GAAS2R,cAAc3M,KAAI,SAAU6P,GAC3E,MAAO,CAACA,GAAMvT,MAAQtB,GAAS2R,aAAakD,GAAKlN,YAChDrG,MAAQtB,GACX,MAAO,CACLiB,QAASZ,KAAKY,QACd4Q,QAASvQ,MAAQtB,GAAS6R,OAC1BF,aAAcA,EACdD,cAAeA,EACfjR,UAAWa,MAAQtB,GAASS,SAASkH;;;;;;KAWzCtH,KAAKmR,MAAMpL,KAAO,SAAU0O,GAC1B,IAAIrD,EAAQ,GACRE,EAAe,GACfoD,EAAoBD,EAAgBnD,aACpCD,EAAgB9P,OAAOC,OAAO,MAC9BmT,EAA0BF,EAAgBpD,cAC1CuD,EAAkB,IAAI5U,KAAKiO,SAAS9N,QACpCC,EAAWJ,KAAKwF,SAASO,KAAK0O,EAAgBrU,UAE9CqU,EAAgB7T,SAAWZ,KAAKY,SAClCZ,KAAKa,MAAMC,KAAK,4EAA8Ed,KAAKY,QAAU,sCAAwC6T,EAAgB7T,QAAU,KAGjL,IAAK,IAAIc,EAAI,EAAGA,EAAIgT,EAAkB/S,OAAQD,IAAK,CACjD,IAAImT,EAAQH,EAAkBhT,GAC1B8S,EAAMK,EAAM,GACZ9R,EAAW8R,EAAM,GACrBvD,EAAakD,GAAO,IAAIxU,KAAKuH,OAAOxE,GAGtC,IAAK,IAAIrB,EAAI,EAAGA,EAAIiT,EAAwBhT,OAAQD,IAAK,CACvD,IAAImT,EAAQF,EAAwBjT,GAChCmN,EAAOgG,EAAM,GACb/Q,EAAU+Q,EAAM,GACpBD,EAAgB5M,OAAO6G,GACvBwC,EAAcxC,GAAQ/K,EAGxB8Q,EAAgBpG,SAChB4C,EAAMI,OAASiD,EAAgBjD,OAC/BJ,EAAME,aAAeA,EACrBF,EAAMC,cAAgBA,EACtBD,EAAMG,SAAWqD,EAAgBnG,KACjC2C,EAAMhR,SAAWA,EACjB,OAAO,IAAIJ,KAAKmR,MAAMC,IAiCxBpR,KAAKG,QAAU,YACZc,MAAQtB,GAASmV,KAAO,MACxB7T,MAAQtB,GAASoV,QAAUxT,OAAOC,OAAO,OACzCP,MAAQtB,GAASqV,WAAazT,OAAOC,OAAO,OAC5CP,MAAQtB,GAAS0R,cAAgB9P,OAAOC,OAAO,OAC/CP,MAAQtB,GAASsV,qBAAuB,IACxChU,MAAQtB,GAASuV,aAAe,IAChCjU,MAAQtB,GAAS+E,UAAY1E,KAAK0E,WAClCzD,MAAQtB,GAASS,SAAW,IAAIJ,KAAKwF,UACrCvE,MAAQtB,GAASc,eAAiB,IAAIT,KAAKwF,UAC3CvE,MAAQtB,GAASoE,cAAgB,GACjC9C,MAAQtB,GAASwV,GAAK,KACtBlU,MAAQtB,GAASyV,IAAM,KACvBnU,MAAQtB,GAASqT,UAAY,GAC7B/R,MAAQtB,GAAS0V,kBAAoB;;;;;;;;;;;;KAgBxCrV,KAAKG,QAAQ0C,UAAU2R,IAAM,SAAUA,IACpCvT,MAAQtB,GAASmV,KAAON;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;KAoC3BxU,KAAKG,QAAQ0C,UAAUiQ,MAAQ,SAAU1Q,EAAWkT,GAClD,GAAI,KAAK9H,KAAKpL,GACZ,MAAM,IAAImT,WAAW,UAAYnT,EAAY,qCAG9CnB,MAAQtB,GAASoV,QAAQ3S,GAAakT,GAAc;;;;;;;;KAYvDtV,KAAKG,QAAQ0C,UAAUW,EAAI,SAAUgS,IAEhCvU,MAAQtB,GAASwV,GADhBK,EAAS,EACY,EACdA,EAAS,EACK,EAEAA;;;;;;;KAY3BxV,KAAKG,QAAQ0C,UAAU4S,GAAK,SAAUD,IACnCvU,MAAQtB,GAASyV,IAAMI;;;;;;;;;;;;;;;;;KAqB1BxV,KAAKG,QAAQ0C,UAAUxC,IAAM,SAAUqV,EAAKJ,GAC1C,IAAInT,EAASuT,GAAKzU,MAAQtB,GAASmV,MAC/BtD,EAASjQ,OAAOE,MAAMR,MAAQtB,GAASoV,UAC1C9T,MAAQtB,GAASqV,WAAW7S,GAAUmT,GAAc,IACpDrU,MAAQtB,GAASoE,eAAiB,EAEnC,IAAK,IAAIrC,EAAI,EAAGA,EAAI8P,EAAO7P,OAAQD,IAAK,CACtC,IAAIU,EAAYoP,EAAO9P,GACnBiU,GAAa1U,MAAQtB,GAASoV,QAAQ3S,GAAWuT,UACjD7C,EAAQ6C,EAAYA,EAAUD,GAAOA,EAAItT,GACzC2C,EAAS9D,KAAKyD,UAAUoO,EAAO,CACjCtB,OAAQ,CAACpP,KAEPkQ,GAASrR,MAAQtB,GAASS,SAASyG,IAAI9B,GACvCnC,EAAW,IAAI5C,KAAKkC,SAASC,EAAQC,GACrCwT,EAAarU,OAAOC,OAAO,OAE9BP,MAAQtB,GAASsV,qBAAqBrS,GAAYgT,GAClD3U,MAAQtB,GAASuV,aAAatS,GAAY,GAE1C3B,MAAQtB,GAASuV,aAAatS,IAAa0P,EAAM3Q,OAElD,IAAK,IAAIqF,EAAI,EAAGA,EAAIsL,EAAM3Q,OAAQqF,IAAK,CACrC,IAAI6H,EAAOyD,EAAMtL,QAEO1F,GAApBsU,EAAW/G,KACb+G,EAAW/G,GAAQ,GAGrB+G,EAAW/G,IAAS,EAGpB,QAA6CvN,IAAxCL,MAAQtB,GAAS0R,cAAcxC,GAAoB,CACtD,IAAI/K,EAAUvC,OAAOC,OAAO,MAC5BsC,EAAQ,WAAa7C,MAAQtB,GAASqT,WACrC/R,MAAQtB,GAASqT,WAAa,EAE/B,IAAK,IAAI9L,EAAI,EAAGA,EAAIsK,EAAO7P,OAAQuF,IACjCpD,EAAQ0N,EAAOtK,IAAM3F,OAAOC,OAAO,OAGpCP,MAAQtB,GAAS0R,cAAcxC,GAAQ/K,OAIsBxC,IAA3DL,MAAQtB,GAAS0R,cAAcxC,GAAMzM,GAAWD,MAClDlB,MAAQtB,GAAS0R,cAAcxC,GAAMzM,GAAWD,GAAUZ,OAAOC,OAAO,OAK3E,IAAK,IAAIgS,EAAI,EAAGA,GAAKvS,MAAQtB,GAAS0V,kBAAkB1T,OAAQ6R,IAAK,CACnE,IAAIqC,GAAe5U,MAAQtB,GAAS0V,kBAAkB7B,GAClDjP,EAAWsK,EAAKtK,SAASsR,QAEgDvU,IAAxEL,MAAQtB,GAAS0R,cAAcxC,GAAMzM,GAAWD,GAAQ0T,MAC1D5U,MAAQtB,GAAS0R,cAAcxC,GAAMzM,GAAWD,GAAQ0T,GAAe,KAGzE5U,MAAQtB,GAAS0R,cAAcxC,GAAMzM,GAAWD,GAAQ0T,GAAalS,KAAKY,OAYnFvE,KAAKG,QAAQ0C,UAAUiT,6BAA+B,WACpD,IAAIC,EAAYxU,OAAOE,MAAMR,MAAQtB,GAASuV,cAC1Cc,EAAiBD,EAAUpU,OAC3BsU,EAAc,GACdC,EAAqB,GAEzB,IAAK,IAAIxU,EAAI,EAAGA,EAAIsU,EAAgBtU,IAAK,CACvC,IAAIkB,EAAW5C,KAAKkC,SAASM,WAAWuT,EAAUrU,IAC9CoR,EAAQlQ,EAASR,UACrB8T,EAAmBpD,KAAWoD,EAAmBpD,GAAS,GAC1DoD,EAAmBpD,IAAU,EAC7BmD,EAAYnD,KAAWmD,EAAYnD,GAAS,GAC5CmD,EAAYnD,KAAW7R,MAAQtB,GAASuV,aAAatS,GAGvD,IAAI4O,EAASjQ,OAAOE,MAAMR,MAAQtB,GAASoV,SAE3C,IAAK,IAAIrT,EAAI,EAAGA,EAAI8P,EAAO7P,OAAQD,IAAK,CACtC,IAAIU,EAAYoP,EAAO9P,GACvBuU,EAAY7T,GAAa6T,EAAY7T,GAAa8T,EAAmB9T,IAGtEnB,MAAQtB,GAASwW,mBAAqBF,GASzCjW,KAAKG,QAAQ0C,UAAUuT,mBAAqB,WAC1C,IAAI9E,EAAe,GACfyE,EAAYxU,OAAOE,MAAMR,MAAQtB,GAASsV,sBAC1CoB,EAAkBN,EAAUpU,OAC5B2U,EAAe/U,OAAOC,OAAO,MAEjC,IAAK,IAAIE,EAAI,EAAGA,EAAI2U,EAAiB3U,IAAK,CACxC,IAAIkB,EAAW5C,KAAKkC,SAASM,WAAWuT,EAAUrU,IAC9CU,EAAYQ,EAASR,UACrBmU,GAAetV,MAAQtB,GAASuV,aAAatS,GAC7CuR,EAAc,IAAInU,KAAKuH,OACvBiP,GAAmBvV,MAAQtB,GAASsV,qBAAqBrS,GACzD0P,EAAQ/Q,OAAOE,KAAK+U,GACpBC,EAAcnE,EAAM3Q,OACxB,IAAI+U,GAAczV,MAAQtB,GAASoV,QAAQ3S,GAAWmR,OAAS,EAC3DoD,GAAY1V,MAAQtB,GAASqV,WAAWpS,EAAST,QAAQoR,OAAS,EAEtE,IAAK,IAAIvM,EAAI,EAAGA,EAAIyP,EAAazP,IAAK,CACpC,IAAI6H,EAAOyD,EAAMtL,GACb4P,EAAKJ,EAAgB3H,GACrBmE,GAAa/R,MAAQtB,GAAS0R,cAAcxC,GAAMoE,OAClDpP,EACAuQ,EACAyC,EAEJ,QAA2BvV,IAAvBgV,EAAazH,GAAqB,CACpChL,EAAM7D,KAAK6D,KAAK5C,MAAQtB,GAAS0R,cAAcxC,IAAQ5N,MAAQtB,GAASoE,eACxEuS,EAAazH,GAAQhL,OAErBA,EAAMyS,EAAazH,GAGrBuF,EAAQvQ,KAAS5C,MAAQtB,GAASyV,IAAM,GAAKwB,KAAQ3V,MAAQtB,GAASyV,KAAO,GAAKnU,MAAQtB,GAASwV,IAAMlU,MAAQtB,GAASwV,IAAMoB,GAAetV,MAAQtB,GAASwW,mBAAmB/T,KAAewU,GAClMxC,GAASsC,EACTtC,GAASuC,EACTE,EAAqB3S,KAAK4S,MAAc,IAAR1C,GAAgB,IAOhDD,EAAYnM,OAAOgL,EAAW6D,GAGhCvF,EAAa1O,GAAYuR,GAG1BlT,MAAQtB,GAAS2R,aAAeA,GASnCtR,KAAKG,QAAQ0C,UAAUkU,eAAiB,YACrC9V,MAAQtB,GAAS4R,SAAWvR,KAAKiO,SAASK,UAAU/M,OAAOE,MAAMR,MAAQtB,GAAS0R,eAAetB;;;;;;;;KAYpG/P,KAAKG,QAAQ0C,UAAUlC,MAAQ,WAC7BM,KAAK6U,+BACL7U,KAAKmV,qBACLnV,KAAK8V,iBACL,OAAO,IAAI/W,KAAKmR,MAAM,CACpBE,eAAgBpQ,MAAQtB,GAAS0R,cACjCC,cAAerQ,MAAQtB,GAAS2R,aAChCC,UAAWtQ,MAAQtB,GAAS4R,SAC5BC,OAAQjQ,OAAOE,MAAMR,MAAQtB,GAASoV,SACtC3U,UAAWa,MAAQtB,GAASc;;;;;;;;;;;;;;KAmBhCT,KAAKG,QAAQ0C,UAAUmU,IAAM,SAAUvS,GACrC,IAAIwS,EAAOnV,MAAMe,UAAUb,MAAMtB,KAAK2F,UAAW,GACjD4Q,EAAKC,QAAQjW,MAAQtB,GACrB8E,EAAG0S,MAAMlW,MAAQtB,EAASsX;;;;;;;;;;;;KAgB5BjX,KAAK4T,UAAY,SAAU/E,EAAMiE,EAAOvO,GACtC,IAAI6S,EAAiB7V,OAAOC,OAAO,MAC/B6V,EAAe9V,OAAOE,KAAK8C,GAAY,IAM3C,IAAK,IAAI7C,EAAI,EAAGA,EAAI2V,EAAa1V,OAAQD,IAAK,CAC5C,IAAIE,EAAMyV,EAAa3V,GACvB0V,EAAexV,GAAO2C,EAAS3C,GAAKI,SAGrCf,MAAQtB,GAAS4E,SAAWhD,OAAOC,OAAO,MAE3C,QAAaF,IAATuN,EAAoB,EACrB5N,MAAQtB,GAAS4E,SAASsK,GAAQtN,OAAOC,OAAO,OAChDP,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAASsE;;;;;;;;;KAc9CpX,KAAK4T,UAAU/Q,UAAU0R,QAAU,SAAU+C,GAC3C,IAAIhF,EAAQ/Q,OAAOE,KAAK6V,EAAe/S,UAEvC,IAAK,IAAI7C,EAAI,EAAGA,EAAI4Q,EAAM3Q,OAAQD,IAAK,CACrC,IAAImN,EAAOyD,EAAM5Q,GACb8P,EAASjQ,OAAOE,KAAK6V,EAAe/S,SAASsK,SAETvN,IAAnCL,MAAQtB,GAAS4E,SAASsK,MAC5B5N,MAAQtB,GAAS4E,SAASsK,GAAQtN,OAAOC,OAAO,OAGnD,IAAK,IAAIwF,EAAI,EAAGA,EAAIwK,EAAO7P,OAAQqF,IAAK,CACtC,IAAI8L,EAAQtB,EAAOxK,GACfvF,EAAOF,OAAOE,KAAK6V,EAAe/S,SAASsK,GAAMiE,SAENxR,IAA1CL,MAAQtB,GAAS4E,SAASsK,GAAMiE,MAClC7R,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAASvR,OAAOC,OAAO,OAG1D,IAAK,IAAI0F,EAAI,EAAGA,EAAIzF,EAAKE,OAAQuF,IAAK,CACpC,IAAItF,EAAMH,EAAKyF,QAEqC5F,IAA/CL,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,IACzCX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,GAAO0V,EAAe/S,SAASsK,GAAMiE,GAAOlR,IAEnFX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,IAAQX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,GAAKgC,OAAO0T,EAAe/S,SAASsK,GAAMiE,GAAOlR;;;;;;;KAelJ5B,KAAK4T,UAAU/Q,UAAUxC,IAAM,SAAUwO,EAAMiE,EAAOvO,GACpD,GAAMsK,KAAS5N,MAAQtB,GAAS4E,SAMhC,GAAMuO,KAAU7R,MAAQtB,GAAS4E,SAASsK,GAA1C,CAKA,IAAIwI,EAAe9V,OAAOE,KAAK8C,GAE/B,IAAK,IAAI7C,EAAI,EAAGA,EAAI2V,EAAa1V,OAAQD,IAAK,CAC5C,IAAIE,EAAMyV,EAAa3V,GAEnBE,KAAQX,MAAQtB,GAAS4E,SAASsK,GAAMiE,IACzC7R,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,IAAQX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,GAAKgC,OAAOW,EAAS3C,KAE3GX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAAOlR,GAAO2C,EAAS3C,SAZzDX,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAASvO,MAP5C,EACGtD,MAAQtB,GAAS4E,SAASsK,GAAQtN,OAAOC,OAAO,OAChDP,MAAQtB,GAAS4E,SAASsK,GAAMiE,GAASvO,IAkC9CvE,KAAK+R,MAAQ,SAAUwF,IACpBtW,MAAQtB,GAAS0S,QAAU,IAC3BpR,MAAQtB,GAAS4X,UAAYA,GA2BhCvX,KAAK+R,MAAMyF,SAAW,IAAIC,OAAO,KACjCzX,KAAK+R,MAAMyF,SAASE,KAAO,EAC3B1X,KAAK+R,MAAMyF,SAASG,QAAU,EAC9B3X,KAAK+R,MAAMyF,SAASI,SAAW,EAa/B5X,KAAK+R,MAAMa,SAAW,CAIpBiF,SAAU,EAMVhF,SAAU,EAMVS,WAAY;;;;;;;;;;;;;;;;;;;;;;KA0BdtT,KAAK+R,MAAMlP,UAAU8L,OAAS,SAAUA,GAChC,WAAYA,IAChBA,EAAO6C,QAAUvQ,MAAQtB,GAAS4X,WAG9B,UAAW5I,IACfA,EAAO4E,MAAQ,GAGX,gBAAiB5E,IACrBA,EAAO6D,YAAc,MAGjB,aAAc7D,IAClBA,EAAO6I,SAAWxX,KAAK+R,MAAMyF,SAASE,MAGpC/I,EAAO6I,SAAWxX,KAAK+R,MAAMyF,SAASG,SAAWhJ,EAAOE,KAAK1J,OAAO,IAAMnF,KAAK+R,MAAMyF,WACvF7I,EAAOE,KAAO,IAAMF,EAAOE,MAGzBF,EAAO6I,SAAWxX,KAAK+R,MAAMyF,SAASI,UAAYjJ,EAAOE,KAAK7M,OAAO,IAAMhC,KAAK+R,MAAMyF,WACxF7I,EAAOE,KAAYF,EAAOE,KAAO,KAG7B,aAAcF,IAClBA,EAAOiE,SAAW5S,KAAK+R,MAAMa,SAASiF,WAGvC5W,MAAQtB,GAAS0S,QAAQ1O,KAAKgL,GAE/B,OAAO1N,MAAQtB;;;;;;;KAWjBK,KAAK+R,MAAMlP,UAAUqR,UAAY,WAC/B,IAAK,IAAIxS,EAAI,EAAGA,GAAKT,MAAQtB,GAAS0S,QAAQ1Q,OAAQD,IACpD,IAAKT,MAAQtB,GAAS0S,QAAQ3Q,GAAGkR,UAAY5S,KAAK+R,MAAMa,SAASU,WAC/D,OAAO,MAIX,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;KA8BTtT,KAAK+R,MAAMlP,UAAUgM,KAAO,SAAUA,EAAMiJ,GAC1C,GAAIhW,MAAMC,QAAQ8M,GAAO,CACvBA,EAAK5I,SAAQ,SAAUrB,GACrB3D,KAAK4N,KAAKjK,EAAG5E,KAAKa,MAAMQ,MAAMyW,MAC7B7W,MAAQtB,GACX,OAAOsB,MAAQtB,EAGjB,IAAIgP,EAASmJ,GAAW,GACxBnJ,EAAOE,KAAOA,EAAKzN,WACnBH,KAAK0N,OAAOA,GACZ,OAAO1N,MAAQtB,GAGjBK,KAAK+X,gBAAkB,SAAUhX,EAAS4G,EAAOC,IAC9C3G,MAAQtB,GAASqY,KAAO,mBACxB/W,MAAQtB,GAASoB,QAAUA,GAC3BE,MAAQtB,GAASgI,MAAQA,GACzB1G,MAAQtB,GAASiI,IAAMA,GAG1B5H,KAAK+X,gBAAgBlV,UAAY,IAAIsD,MAErCnG,KAAKiY,WAAa,SAAU3T,IACzBrD,MAAQtB,GAASuY,QAAU,IAC3BjX,MAAQtB,GAAS2E,IAAMA,GACvBrD,MAAQtB,GAASgC,OAAS2C,EAAI3C,QAC9BV,MAAQtB,GAAS8G,IAAM,GACvBxF,MAAQtB,GAASgI,MAAQ,GACzB1G,MAAQtB,GAASwY,oBAAsB,IAG1CnY,KAAKiY,WAAWpV,UAAUgE,IAAM,WAC9B,IAAIuR,EAAQpY,KAAKiY,WAAWI,QAE5B,MAAOD,EACLA,EAAQA,EAAMnX,MAAQtB,IAI1BK,KAAKiY,WAAWpV,UAAUyV,YAAc,WACtC,IAAIC,EAAY,GACZtT,GAAchE,MAAQtB,GAASgI,MAC/B3C,GAAY/D,MAAQtB,GAAS8G,IAEjC,IAAK,IAAI/E,EAAI,EAAGA,GAAKT,MAAQtB,GAASwY,oBAAoBxW,OAAQD,IAAK,CACrEsD,GAAY/D,MAAQtB,GAASwY,oBAAoBzW,GACjD6W,EAAU5U,MAAM1C,MAAQtB,GAAS2E,IAAItC,MAAMiD,EAAYD,IACvDC,EAAaD,EAAW,EAG1BuT,EAAU5U,MAAM1C,MAAQtB,GAAS2E,IAAItC,MAAMiD,GAAahE,MAAQtB,GAAS8G,OACxExF,MAAQtB,GAASwY,oBAAoBxW,OAAS,EAC/C,OAAO4W,EAAUC,KAAK,KAGxBxY,KAAKiY,WAAWpV,UAAU4V,KAAO,SAAUC,IACxCzX,MAAQtB,GAASuY,QAAQvU,KAAK,CAC7B+U,KAAMA,EACNpU,IAAKrD,KAAKqX,cACV3Q,OAAQ1G,MAAQtB,GAASgI,MACzBC,KAAM3G,MAAQtB,GAAS8G,OAGxBxF,MAAQtB,GAASgI,OAAS1G,MAAQtB,GAAS8G,KAG9CzG,KAAKiY,WAAWpV,UAAU8V,gBAAkB,YACzC1X,MAAQtB,GAASwY,oBAAoBxU,MAAM1C,MAAQtB,GAAS8G,IAAM,IAElExF,MAAQtB,GAAS8G,KAAO,GAG3BzG,KAAKiY,WAAWpV,UAAU6M,KAAO,WAC/B,IAAKzO,MAAQtB,GAAS8G,MAAQxF,MAAQtB,GAASgC,OAC7C,OAAO3B,KAAKiY,WAAWW,IAGzB,IAAI1T,GAAQjE,MAAQtB,GAAS2E,IAAIa,QAAQlE,MAAQtB,GAAS8G,MAEzDxF,MAAQtB,GAAS8G,KAAO,EACzB,OAAOvB,GAGTlF,KAAKiY,WAAWpV,UAAUgW,MAAQ,WAChC,OAAQ5X,MAAQtB,GAAS8G,KAAOxF,MAAQtB,GAASgI,OAGnD3H,KAAKiY,WAAWpV,UAAUiW,OAAS,YAC5B7X,MAAQtB,GAASgI,QAAU1G,MAAQtB,GAAS8G,OAC9CxF,MAAQtB,GAAS8G,KAAO,IAG1BxF,MAAQtB,GAASgI,OAAS1G,MAAQtB,GAAS8G,KAG9CzG,KAAKiY,WAAWpV,UAAUkW,OAAS,YAChC9X,MAAQtB,GAAS8G,KAAO,GAG3BzG,KAAKiY,WAAWpV,UAAUmW,eAAiB,WACzC,IAAI9T,EAAM+T,EAEV,EAAG,CACD/T,EAAOjE,KAAKyO,OACZuJ,EAAW/T,EAAKgU,WAAW,SACpBD,EAAW,IAAMA,EAAW,IAEjC/T,GAAQlF,KAAKiY,WAAWW,KAC1B3X,KAAK8X,UAIT/Y,KAAKiY,WAAWpV,UAAUsW,KAAO,WAC/B,OAAQlY,MAAQtB,GAAS8G,KAAOxF,MAAQtB,GAASgC,QAGnD3B,KAAKiY,WAAWW,IAAM,MACtB5Y,KAAKiY,WAAWmB,MAAQ,QACxBpZ,KAAKiY,WAAWoB,KAAO,OACvBrZ,KAAKiY,WAAWqB,cAAgB,gBAChCtZ,KAAKiY,WAAWsB,MAAQ,QACxBvZ,KAAKiY,WAAWuB,SAAW,WAE3BxZ,KAAKiY,WAAWwB,SAAW,SAAUC,GACnCA,EAAMX,SACNW,EAAMjB,KAAKzY,KAAKiY,WAAWmB,OAC3BM,EAAMZ,SACN,OAAO9Y,KAAKiY,WAAWI,SAGzBrY,KAAKiY,WAAW0B,QAAU,SAAUD,GAClC,GAAIA,EAAMb,QAAU,EAAG,CACrBa,EAAMX,SACNW,EAAMjB,KAAKzY,KAAKiY,WAAWoB,MAG7BK,EAAMZ,SAEN,GAAIY,EAAMP,OACR,OAAOnZ,KAAKiY,WAAWI,SAI3BrY,KAAKiY,WAAW2B,gBAAkB,SAAUF,GAC1CA,EAAMZ,SACNY,EAAMV,iBACNU,EAAMjB,KAAKzY,KAAKiY,WAAWqB,eAC3B,OAAOtZ,KAAKiY,WAAWI,SAGzBrY,KAAKiY,WAAW4B,SAAW,SAAUH,GACnCA,EAAMZ,SACNY,EAAMV,iBACNU,EAAMjB,KAAKzY,KAAKiY,WAAWsB,OAC3B,OAAOvZ,KAAKiY,WAAWI,SAGzBrY,KAAKiY,WAAW6B,OAAS,SAAUJ,GAC7BA,EAAMb,QAAU,GAClBa,EAAMjB,KAAKzY,KAAKiY,WAAWoB,OAe/BrZ,KAAKiY,WAAW8B,cAAgB/Z,KAAK0E,UAAUY,UAE/CtF,KAAKiY,WAAWI,QAAU,SAAUqB,GAClC,MAAO,KAAM,CACX,IAAIxU,EAAOwU,EAAMhK,OAEjB,GAAIxK,GAAQlF,KAAKiY,WAAWW,IAC1B,OAAO5Y,KAAKiY,WAAW6B,OAIzB,GAA0B,IAAtB5U,EAAKgU,WAAW,GAApB,CAKA,GAAY,KAARhU,EACF,OAAOlF,KAAKiY,WAAWwB,SAGzB,GAAY,KAARvU,EAAa,CACfwU,EAAMX,SAEFW,EAAMb,QAAU,GAClBa,EAAMjB,KAAKzY,KAAKiY,WAAWoB,MAG7B,OAAOrZ,KAAKiY,WAAW2B,gBAGzB,GAAY,KAAR1U,EAAa,CACfwU,EAAMX,SAEFW,EAAMb,QAAU,GAClBa,EAAMjB,KAAKzY,KAAKiY,WAAWoB,MAG7B,OAAOrZ,KAAKiY,WAAW4B,SAMzB,GAAY,KAAR3U,GAAiC,IAAlBwU,EAAMb,QAAe,CACtCa,EAAMjB,KAAKzY,KAAKiY,WAAWuB,UAC3B,OAAOxZ,KAAKiY,WAAWI,QAMzB,GAAY,KAARnT,GAAiC,IAAlBwU,EAAMb,QAAe,CACtCa,EAAMjB,KAAKzY,KAAKiY,WAAWuB,UAC3B,OAAOxZ,KAAKiY,WAAWI,QAGzB,GAAInT,EAAKG,MAAMrF,KAAKiY,WAAW8B,eAC7B,OAAO/Z,KAAKiY,WAAW0B,aA7CvBD,EAAMf,oBAkDZ3Y,KAAK6R,YAAc,SAAUvN,EAAKqN,IAC/B1Q,MAAQtB,GAAS+Z,MAAQ,IAAI1Z,KAAKiY,WAAW3T,IAC7CrD,MAAQtB,GAASgS,MAAQA,GACzB1Q,MAAQtB,GAASqa,cAAgB,IACjC/Y,MAAQtB,GAASsa,UAAY,GAGhCja,KAAK6R,YAAYhP,UAAUiP,MAAQ,YAChC7Q,MAAQtB,GAAS+Z,MAAM7S,OAEvB5F,MAAQtB,GAASuY,SAAWjX,MAAQtB,GAAS+Z,MAAMxB,QACpD,IAAIE,EAAQpY,KAAK6R,YAAYqI,YAE7B,MAAO9B,EACLA,EAAQA,EAAMnX,MAAQtB,GAGxB,OAAQsB,MAAQtB,GAASgS,OAG3B3R,KAAK6R,YAAYhP,UAAUsX,WAAa,WACtC,OAAQlZ,MAAQtB,GAASuY,SAASjX,MAAQtB,GAASsa,YAGrDja,KAAK6R,YAAYhP,UAAUuX,cAAgB,WACzC,IAAIC,EAASpZ,KAAKkZ,cACjBlZ,MAAQtB,GAASsa,WAAa,EAC/B,OAAOI,GAGTra,KAAK6R,YAAYhP,UAAUyX,WAAa,WACtC,IAAIC,GAAmBtZ,MAAQtB,GAASqa,eAEvC/Y,MAAQtB,GAASgS,MAAMhD,OAAO4L,IAE9BtZ,MAAQtB,GAASqa,cAAgB,IAGpCha,KAAK6R,YAAYqI,YAAc,SAAUtI,GACvC,IAAIyI,EAASzI,EAAOuI,aAEpB,QAAc7Y,GAAV+Y,EAIJ,OAAQA,EAAO3B,MACb,KAAK1Y,KAAKiY,WAAWuB,SACnB,OAAOxZ,KAAK6R,YAAY2I,cAE1B,KAAKxa,KAAKiY,WAAWmB,MACnB,OAAOpZ,KAAK6R,YAAY4I,WAE1B,KAAKza,KAAKiY,WAAWoB,KACnB,OAAOrZ,KAAK6R,YAAY6I,UAE1B,QACE,IAAIC,EAAe,4CAA8CN,EAAO3B,KAEpE2B,EAAO/V,IAAI3C,QAAU,IACvBgZ,GAAgB,gBAAkBN,EAAO/V,IAAM,KAGjD,MAAM,IAAItE,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,OAIxE5H,KAAK6R,YAAY2I,cAAgB,SAAU5I,GACzC,IAAIyI,EAASzI,EAAOwI,gBAEpB,QAAc9Y,GAAV+Y,EAAJ,CAIA,OAAQA,EAAO/V,KACb,IAAK,IACHsN,EAAOoI,cAAcpH,SAAW5S,KAAK+R,MAAMa,SAASU,WACpD,MAEF,IAAK,IACH1B,EAAOoI,cAAcpH,SAAW5S,KAAK+R,MAAMa,SAASC,SACpD,MAEF,QACE,IAAI8H,EAAe,kCAAoCN,EAAO/V,IAAM,IACpE,MAAM,IAAItE,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGtE,IAAIgT,EAAahJ,EAAOuI,aAExB,QAAkB7Y,GAAdsZ,EAAyB,CAC3B,IAAID,EAAe,yCACnB,MAAM,IAAI3a,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGpE,OAAQgT,EAAWlC,MACjB,KAAK1Y,KAAKiY,WAAWmB,MACnB,OAAOpZ,KAAK6R,YAAY4I,WAE1B,KAAKza,KAAKiY,WAAWoB,KACnB,OAAOrZ,KAAK6R,YAAY6I,UAE1B,QACE,IAAIC,EAAe,mCAAqCC,EAAWlC,KAAO,IAC1E,MAAM,IAAI1Y,KAAK+X,gBAAgB4C,EAAcC,EAAWjT,MAAOiT,EAAWhT,QAIhF5H,KAAK6R,YAAY4I,WAAa,SAAU7I,GACtC,IAAIyI,EAASzI,EAAOwI,gBAEpB,QAAc9Y,GAAV+Y,EAAJ,CAIA,IAAmD,GAA/CzI,EAAOD,MAAM4F,UAAU5U,QAAQ0X,EAAO/V,KAAY,CACpD,IAAIuW,EAAiBjJ,EAAOD,MAAM4F,UAAU5S,KAAI,SAAUmW,GACxD,MAAO,IAAMA,EAAI,OAChBtC,KAAK,MACJmC,EAAe,uBAAyBN,EAAO/V,IAAM,uBAAyBuW,EAClF,MAAM,IAAI7a,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGpEgK,EAAOoI,cAAcxI,OAAS,CAAC6I,EAAO/V,KACtC,IAAIsW,EAAahJ,EAAOuI,aAExB,QAAkB7Y,GAAdsZ,EAAyB,CAC3B,IAAID,EAAe,gCACnB,MAAM,IAAI3a,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGpE,OAAQgT,EAAWlC,MACjB,KAAK1Y,KAAKiY,WAAWoB,KACnB,OAAOrZ,KAAK6R,YAAY6I,UAE1B,QACE,IAAIC,EAAe,0BAA4BC,EAAWlC,KAAO,IACjE,MAAM,IAAI1Y,KAAK+X,gBAAgB4C,EAAcC,EAAWjT,MAAOiT,EAAWhT,QAIhF5H,KAAK6R,YAAY6I,UAAY,SAAU9I,GACrC,IAAIyI,EAASzI,EAAOwI,gBAEpB,QAAc9Y,GAAV+Y,EAAJ,CAIAzI,EAAOoI,cAAcnL,KAAOwL,EAAO/V,IAAIO,eAEP,GAA5BwV,EAAO/V,IAAI3B,QAAQ,OACrBiP,EAAOoI,cAAcxH,YAAc,OAGrC,IAAIoI,EAAahJ,EAAOuI,aAExB,QAAkB7Y,GAAdsZ,EAKJ,OAAQA,EAAWlC,MACjB,KAAK1Y,KAAKiY,WAAWoB,KACnBzH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY6I,UAE1B,KAAK1a,KAAKiY,WAAWmB,MACnBxH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY4I,WAE1B,KAAKza,KAAKiY,WAAWqB,cACnB,OAAOtZ,KAAK6R,YAAYkJ,kBAE1B,KAAK/a,KAAKiY,WAAWsB,MACnB,OAAOvZ,KAAK6R,YAAYmJ,WAE1B,KAAKhb,KAAKiY,WAAWuB,SACnB5H,EAAO0I,aACP,OAAOta,KAAK6R,YAAY2I,cAE1B,QACE,IAAIG,EAAe,2BAA6BC,EAAWlC,KAAO,IAClE,MAAM,IAAI1Y,KAAK+X,gBAAgB4C,EAAcC,EAAWjT,MAAOiT,EAAWhT,UAzB5EgK,EAAO0I,eA6BXta,KAAK6R,YAAYkJ,kBAAoB,SAAUnJ,GAC7C,IAAIyI,EAASzI,EAAOwI,gBAEpB,QAAc9Y,GAAV+Y,EAAJ,CAIA,IAAIvL,EAAemM,SAASZ,EAAO/V,IAAK,IAExC,GAAI4W,MAAMpM,GAAe,CACvB,IAAI6L,EAAe,gCACnB,MAAM,IAAI3a,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGpEgK,EAAOoI,cAAclL,aAAeA,EACpC,IAAI8L,EAAahJ,EAAOuI,aAExB,QAAkB7Y,GAAdsZ,EAKJ,OAAQA,EAAWlC,MACjB,KAAK1Y,KAAKiY,WAAWoB,KACnBzH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY6I,UAE1B,KAAK1a,KAAKiY,WAAWmB,MACnBxH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY4I,WAE1B,KAAKza,KAAKiY,WAAWqB,cACnB,OAAOtZ,KAAK6R,YAAYkJ,kBAE1B,KAAK/a,KAAKiY,WAAWsB,MACnB,OAAOvZ,KAAK6R,YAAYmJ,WAE1B,KAAKhb,KAAKiY,WAAWuB,SACnB5H,EAAO0I,aACP,OAAOta,KAAK6R,YAAY2I,cAE1B,QACE,IAAIG,EAAe,2BAA6BC,EAAWlC,KAAO,IAClE,MAAM,IAAI1Y,KAAK+X,gBAAgB4C,EAAcC,EAAWjT,MAAOiT,EAAWhT,UAzB5EgK,EAAO0I,eA6BXta,KAAK6R,YAAYmJ,WAAa,SAAUpJ,GACtC,IAAIyI,EAASzI,EAAOwI,gBAEpB,QAAc9Y,GAAV+Y,EAAJ,CAIA,IAAI9G,EAAQ0H,SAASZ,EAAO/V,IAAK,IAEjC,GAAI4W,MAAM3H,GAAQ,CAChB,IAAIoH,EAAe,wBACnB,MAAM,IAAI3a,KAAK+X,gBAAgB4C,EAAcN,EAAO1S,MAAO0S,EAAOzS,KAGpEgK,EAAOoI,cAAczG,MAAQA,EAC7B,IAAIqH,EAAahJ,EAAOuI,aAExB,QAAkB7Y,GAAdsZ,EAKJ,OAAQA,EAAWlC,MACjB,KAAK1Y,KAAKiY,WAAWoB,KACnBzH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY6I,UAE1B,KAAK1a,KAAKiY,WAAWmB,MACnBxH,EAAO0I,aACP,OAAOta,KAAK6R,YAAY4I,WAE1B,KAAKza,KAAKiY,WAAWqB,cACnB,OAAOtZ,KAAK6R,YAAYkJ,kBAE1B,KAAK/a,KAAKiY,WAAWsB,MACnB,OAAOvZ,KAAK6R,YAAYmJ,WAE1B,KAAKhb,KAAKiY,WAAWuB,SACnB5H,EAAO0I,aACP,OAAOta,KAAK6R,YAAY2I,cAE1B,QACE,IAAIG,EAAe,2BAA6BC,EAAWlC,KAAO,IAClE,MAAM,IAAI1Y,KAAK+X,gBAAgB4C,EAAcC,EAAWjT,MAAOiT,EAAWhT,UAzB5EgK,EAAO0I,gBAkCX,SAAW7L,EAAM0M,GAMfpb,EAAUob,KANZ,CAOGla,MAAQtB,GAAS,WAMlB,OAAOK,SAp1GX,GAw1GA,MAAeD"}